{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoGfcfU2jwRJ"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBSRrFankigy",
        "outputId": "635373a0-cdb2-4ac3-856e-3fc08934b134"
      },
      "source": [
        "pip install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u-6ovaqkx6h"
      },
      "source": [
        "train=pd.read_csv(\"Sarcasm_Dataset.csv\",delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "odtEztEtmAfm",
        "outputId": "a79fbc0b-cadc-4db0-d2d1-d7f563a30fc0"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>irony</th>\n",
              "      <th>satire</th>\n",
              "      <th>understatement</th>\n",
              "      <th>overstatement</th>\n",
              "      <th>rhetorical_question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>3463</td>\n",
              "      <td>The population spike in Chicago in 9 months is...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>3464</td>\n",
              "      <td>You'd think in the second to last English clas...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>3465</td>\n",
              "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>3466</td>\n",
              "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>3467</td>\n",
              "      <td>Overheard as my 13 year old games with a frien...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3468 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... rhetorical_question\n",
              "0              0  ...                 0.0\n",
              "1              1  ...                 0.0\n",
              "2              2  ...                 0.0\n",
              "3              3  ...                 0.0\n",
              "4              4  ...                 0.0\n",
              "...          ...  ...                 ...\n",
              "3463        3463  ...                 NaN\n",
              "3464        3464  ...                 NaN\n",
              "3465        3465  ...                 NaN\n",
              "3466        3466  ...                 NaN\n",
              "3467        3467  ...                 NaN\n",
              "\n",
              "[3468 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se8jzZ39mFIo"
      },
      "source": [
        "# Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Npjfe2RQmBT7",
        "outputId": "94e4ba9e-b1b1-493c-d1f9-8c9c65cba054"
      },
      "source": [
        "col_list = [\"tweet\", \"sarcastic\"]\n",
        "df = pd.read_csv(\"Sarcasm_Dataset.csv\", usecols=col_list)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>The population spike in Chicago in 9 months is...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>You'd think in the second to last English clas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>Overheard as my 13 year old games with a frien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3468 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  sarcastic\n",
              "0     The only thing I got from college is a caffein...          1\n",
              "1     I love it when professors draw a big question ...          1\n",
              "2     Remember the hundred emails from companies whe...          1\n",
              "3     Today my pop-pop told me I was not “forced” to...          1\n",
              "4     @VolphanCarol @littlewhitty @mysticalmanatee I...          1\n",
              "...                                                 ...        ...\n",
              "3463  The population spike in Chicago in 9 months is...          0\n",
              "3464  You'd think in the second to last English clas...          0\n",
              "3465  I’m finally surfacing after a holiday to Scotl...          0\n",
              "3466  Couldn't be prouder today. Well done to every ...          0\n",
              "3467  Overheard as my 13 year old games with a frien...          0\n",
              "\n",
              "[3468 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCAG86MioDlt",
        "outputId": "cfedace2-b820-4566-db85-0fc3c45bd55e"
      },
      "source": [
        "#Sample tweet\n",
        "print(df['tweet'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The only thing I got from college is a caffeine addiction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShOW4IFJpJEk"
      },
      "source": [
        "# Text Pre-Processing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ePsvL-mpE3N"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords=stopwords.words(\"english\")\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUufQrImpRy0"
      },
      "source": [
        "def clean_tweets(raw_text,stopwords=stopwords):\n",
        "    '''Golden function for cleaning text data'''\n",
        "    \n",
        "    # Removing HTML Tags\n",
        "    html_removed_text=BeautifulSoup(raw_text).get_text()\n",
        "    \n",
        "    # Remove any non character\n",
        "    character_only_text=re.sub(\"[^a-zA-Z]\",\" \",html_removed_text)\n",
        "    \n",
        "    # Lowercase and split\n",
        "    lower_text=character_only_text.lower().split()\n",
        "    #Get STOPWORDS and remove\n",
        "    stop_remove_text=[i for i in lower_text if not i in stopwords]\n",
        "    \n",
        "    #Lemmatization\n",
        "    lemma_removed_text=[wordnet_lemmatizer.lemmatize(word,'v') for word in stop_remove_text]\n",
        "    \n",
        "    # Remove one character words\n",
        "    lemma_removed_text=[word for word in stop_remove_text if len(word)>1]\n",
        "    \n",
        "    return \" \".join(lemma_removed_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vBoDouZppYsB",
        "outputId": "b4142b9b-21fd-4316-b387-7a491c82b67a"
      },
      "source": [
        "# check on sample\n",
        "df.loc[:1,\"tweet\"].apply(clean_tweets)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'thing got college caffeine addiction'"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ROok0vE_peWa",
        "outputId": "11fe8c19-fb7f-49aa-8581-b9e9665cc505"
      },
      "source": [
        "# original Review\n",
        "df.loc[0,\"tweet\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The only thing I got from college is a caffeine addiction'"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT2exWMKt5jm"
      },
      "source": [
        "df.dropna(subset = [\"tweet\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "MSf02iB6pngu",
        "outputId": "9478ee2b-587f-404e-caeb-bdecd251296f"
      },
      "source": [
        "df['clean_tweet']=df['tweet'].apply(clean_tweets)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/jpgi5N4U9C\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcastic</th>\n",
              "      <th>clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The only thing I got from college is a caffein...</td>\n",
              "      <td>1</td>\n",
              "      <td>thing got college caffeine addiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love it when professors draw a big question ...</td>\n",
              "      <td>1</td>\n",
              "      <td>love professors draw big question mark next an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Remember the hundred emails from companies whe...</td>\n",
              "      <td>1</td>\n",
              "      <td>remember hundred emails companies covid starte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
              "      <td>1</td>\n",
              "      <td>today pop pop told forced go college okay sure...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
              "      <td>1</td>\n",
              "      <td>volphancarol littlewhitty mysticalmanatee also...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3463</th>\n",
              "      <td>The population spike in Chicago in 9 months is...</td>\n",
              "      <td>0</td>\n",
              "      <td>population spike chicago months ridiculous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3464</th>\n",
              "      <td>You'd think in the second to last English clas...</td>\n",
              "      <td>0</td>\n",
              "      <td>think second last english class year prof woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3465</th>\n",
              "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
              "      <td>0</td>\n",
              "      <td>finally surfacing holiday scotland difficult d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3466</th>\n",
              "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
              "      <td>0</td>\n",
              "      <td>prouder today well done every student got gcse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3467</th>\n",
              "      <td>Overheard as my 13 year old games with a frien...</td>\n",
              "      <td>0</td>\n",
              "      <td>overheard year old games friend smell like tar...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3467 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  ...                                        clean_tweet\n",
              "0     The only thing I got from college is a caffein...  ...               thing got college caffeine addiction\n",
              "1     I love it when professors draw a big question ...  ...  love professors draw big question mark next an...\n",
              "2     Remember the hundred emails from companies whe...  ...  remember hundred emails companies covid starte...\n",
              "3     Today my pop-pop told me I was not “forced” to...  ...  today pop pop told forced go college okay sure...\n",
              "4     @VolphanCarol @littlewhitty @mysticalmanatee I...  ...  volphancarol littlewhitty mysticalmanatee also...\n",
              "...                                                 ...  ...                                                ...\n",
              "3463  The population spike in Chicago in 9 months is...  ...         population spike chicago months ridiculous\n",
              "3464  You'd think in the second to last English clas...  ...  think second last english class year prof woul...\n",
              "3465  I’m finally surfacing after a holiday to Scotl...  ...  finally surfacing holiday scotland difficult d...\n",
              "3466  Couldn't be prouder today. Well done to every ...  ...  prouder today well done every student got gcse...\n",
              "3467  Overheard as my 13 year old games with a frien...  ...  overheard year old games friend smell like tar...\n",
              "\n",
              "[3467 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykj1-ciqp1yO"
      },
      "source": [
        "from collections import Counter\n",
        "word_counter=Counter(\" \".join(df['clean_tweet'].tolist()).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSSpWEXIuLbx",
        "outputId": "ebcf651b-17f0-44f2-a73c-3d752cb10b89"
      },
      "source": [
        "word_counter.most_common(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('co', 295), ('https', 282), ('like', 271), ('love', 217)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYYJlN1luQJQ"
      },
      "source": [
        "#Top Words in negative reviews\n",
        "negative_word_counter=Counter(\" \".join(df.loc[df['sarcastic']==1,'clean_tweet'].tolist()).split())\n",
        "\n",
        "#Top words in positive reviews\n",
        "positive_word_counter=Counter(\" \".join(df.loc[df['sarcastic']==0,'clean_tweet'].tolist()).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQR6fYGVuYUK",
        "outputId": "d8d29c1f-2f45-46eb-ecdd-cbab8e758a2e"
      },
      "source": [
        "negative_word_counter.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 84),\n",
              " ('like', 70),\n",
              " ('get', 59),\n",
              " ('day', 59),\n",
              " ('one', 44),\n",
              " ('time', 44),\n",
              " ('people', 42),\n",
              " ('co', 41),\n",
              " ('really', 41),\n",
              " ('https', 39)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkwr0hYZvMBK",
        "outputId": "a31dbecf-d50e-41a4-aec5-2142a271d49a"
      },
      "source": [
        "positive_word_counter.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('co', 254),\n",
              " ('https', 243),\n",
              " ('like', 201),\n",
              " ('one', 164),\n",
              " ('time', 156),\n",
              " ('get', 152),\n",
              " ('people', 148),\n",
              " ('love', 133),\n",
              " ('day', 114),\n",
              " ('really', 107)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FXl2cZ_vWmo"
      },
      "source": [
        "# Baseline Model\n",
        "# Here we see a high overlap in unigram between two categories(here its positive or negative)\n",
        "# Then the next thing we should try is to look for bigrams or trigrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csOGMWA_vkYa"
      },
      "source": [
        "# Bag of Words - Model\n",
        "# Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeaLSjIjvQsk"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNIgd_h-v11-"
      },
      "source": [
        "Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W0XsL8iv1EI"
      },
      "source": [
        "X=df['clean_tweet'] #Predictor\n",
        "y=df['sarcastic'] #Target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ijar0GGv9bx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkDDDfzRwEbg"
      },
      "source": [
        "def create_vector(vectorizer,data):\n",
        "    '''Pass vectorizer and data'''\n",
        "    train_vector=vectorizer.transform(data.tolist())\n",
        "    return train_vector.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRFRfW0iwHDU",
        "outputId": "ad581f6c-02d8-4c99-8509-b096ec37c93f"
      },
      "source": [
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "vectorizer.fit(X_train.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YDaLHlUwXb3"
      },
      "source": [
        "X_train_vector=create_vector(vectorizer,X_train)\n",
        "X_test_vector=create_vector(vectorizer,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8hWhk0awZ2z",
        "outputId": "6306a728-771f-4c61-ee36-099b0f366c86"
      },
      "source": [
        "X_test_vector.shape, X_train_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1145, 1000), (2322, 1000))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWsG3sPQwjig"
      },
      "source": [
        "# Create ML Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L9_vqOPwbnK",
        "outputId": "d1bdba5f-a314-4ee1-a419-6937a79b5338"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "forest=RandomForestClassifier()\n",
        "forest.fit(X_train_vector,y_train)\n",
        "\n",
        "y_pred=forest.predict(X_test_vector)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.88      0.81       840\n",
            "           1       0.36      0.19      0.25       305\n",
            "\n",
            "    accuracy                           0.69      1145\n",
            "   macro avg       0.55      0.53      0.53      1145\n",
            "weighted avg       0.65      0.69      0.66      1145\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK9BhUXzx5Vy"
      },
      "source": [
        "# TFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84hA3mwfwxti"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "transformer = TfidfTransformer(smooth_idf=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kRlgH4QyqBD"
      },
      "source": [
        "tfidf = transformer.fit_transform(X_train_vector)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}