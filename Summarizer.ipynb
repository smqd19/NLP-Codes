{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summarizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a433479dce9d4e3cac7458d66f2e18d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e28f237b49a048f784cf74eb2382bef8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ddee5da4cb24ddc9652d5cd98d22c8f",
              "IPY_MODEL_7aab6fac1a324e848f369228ebe28ad8",
              "IPY_MODEL_eeb57a4cb0c64498ae6063eb8a32cce6"
            ]
          }
        },
        "e28f237b49a048f784cf74eb2382bef8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ddee5da4cb24ddc9652d5cd98d22c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f58650cd9b8b48fe9fa061a7a976a40e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdc4609d508a4910a42bcf5c5bf42c84"
          }
        },
        "7aab6fac1a324e848f369228ebe28ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0e73908bfe0b46edb527e66192b10d6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c762938a472d4c18b614b6f04be1b072"
          }
        },
        "eeb57a4cb0c64498ae6063eb8a32cce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f773841b0964cdeacad9ac07a893790",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:00&lt;00:00, 13.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94c9d93365ce4920b1bf0c6b8218a04a"
          }
        },
        "f58650cd9b8b48fe9fa061a7a976a40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdc4609d508a4910a42bcf5c5bf42c84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e73908bfe0b46edb527e66192b10d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c762938a472d4c18b614b6f04be1b072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f773841b0964cdeacad9ac07a893790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94c9d93365ce4920b1bf0c6b8218a04a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "497994215bb24fd4a170f6ae2c217b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a50c40ca107a401293e7be06456dba43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b65cfb69b8342b3b28b7344eeeffc3a",
              "IPY_MODEL_b272dd7f223c499db31c4c0743217f06",
              "IPY_MODEL_bee1ec7dee384a268e4e06eac2d4f596"
            ]
          }
        },
        "a50c40ca107a401293e7be06456dba43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b65cfb69b8342b3b28b7344eeeffc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f23d0478268460f8123d1c432d1f7bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3d4337e99da42618bcd6b4bbd34e535"
          }
        },
        "b272dd7f223c499db31c4c0743217f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d194d1458ac24dfca5e9d1f70d8fb69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1344997306,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1344997306,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de8d5d3be3447c1b1e5e7c89231dcea"
          }
        },
        "bee1ec7dee384a268e4e06eac2d4f596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4be4ebb4458439493c85bc118334ea1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.25G/1.25G [00:47&lt;00:00, 27.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc35df6370664c659d3add69c2675c95"
          }
        },
        "9f23d0478268460f8123d1c432d1f7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3d4337e99da42618bcd6b4bbd34e535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d194d1458ac24dfca5e9d1f70d8fb69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de8d5d3be3447c1b1e5e7c89231dcea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4be4ebb4458439493c85bc118334ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc35df6370664c659d3add69c2675c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "324b0f1c1c254d289b5a5d08c5787f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_116b2ae2173e48aca10f4a4a338267da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92497e45f1104776a744a2e096f15869",
              "IPY_MODEL_b95b4a90e80642418e92373ea6b81989",
              "IPY_MODEL_cf3310cdc3994ca284dcc3740b991733"
            ]
          }
        },
        "116b2ae2173e48aca10f4a4a338267da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92497e45f1104776a744a2e096f15869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ebe3fc679de4134919d6002cf6786da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5810a4d538d846e09898eca8ab32555f"
          }
        },
        "b95b4a90e80642418e92373ea6b81989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0c780f0696f540f494b6ebec53a536aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdcfb66518f34a63befd01bf9a11018f"
          }
        },
        "cf3310cdc3994ca284dcc3740b991733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5588d0c00b254f569254cfb7daca6a34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 901kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04d58a90a4b2425cbc453ac0fb4f2451"
          }
        },
        "3ebe3fc679de4134919d6002cf6786da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5810a4d538d846e09898eca8ab32555f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c780f0696f540f494b6ebec53a536aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdcfb66518f34a63befd01bf9a11018f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5588d0c00b254f569254cfb7daca6a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04d58a90a4b2425cbc453ac0fb4f2451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3eee67378ca146db8437c5781624c9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ef92399ace44c4a9bbcd329675f3899",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_077a834c5bcc4ec8875004d3a94773e2",
              "IPY_MODEL_cf4609e8a79d4c968ff5bf4573c513ee",
              "IPY_MODEL_00d5ff9ccefc40feb4f45cc931da9a2a"
            ]
          }
        },
        "8ef92399ace44c4a9bbcd329675f3899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "077a834c5bcc4ec8875004d3a94773e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d73a727ba4f1456d9cad79576cb35711",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d2afbcbbe184c1fb369533eeb7937ae"
          }
        },
        "cf4609e8a79d4c968ff5bf4573c513ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03a0041e28b84febb7d11d8f14e1af70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eabfcc69aa00428dbad0c422c8d46471"
          }
        },
        "00d5ff9ccefc40feb4f45cc931da9a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1289c560ca0413a8adcbc3a86775b1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 610B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d2939c5a35c4bf2b848842f3a1cfd95"
          }
        },
        "d73a727ba4f1456d9cad79576cb35711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d2afbcbbe184c1fb369533eeb7937ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03a0041e28b84febb7d11d8f14e1af70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eabfcc69aa00428dbad0c422c8d46471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1289c560ca0413a8adcbc3a86775b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d2939c5a35c4bf2b848842f3a1cfd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f35eb19c90343718f49de6d8f325ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_20dd74cad67f49bd8b743e482e68fc3e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1af2b3f06dda46fb90edc6600acaa3cb",
              "IPY_MODEL_a2d638bb0cf34488bc0993c132d91f1d",
              "IPY_MODEL_90c905ecb2db4ec1941f689be3f02896"
            ]
          }
        },
        "20dd74cad67f49bd8b743e482e68fc3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1af2b3f06dda46fb90edc6600acaa3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc71df2d12cf4bd2be081ef8dacd7e2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4216e661c2c74e2a9ccdf1ddc549c212"
          }
        },
        "a2d638bb0cf34488bc0993c132d91f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe3698ecddb74af2be89eb3a4f2d11ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca75bf63422643e297cda65b4d239504"
          }
        },
        "90c905ecb2db4ec1941f689be3f02896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5eaa9c94a494c038fd92c316e304850",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 679kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54c40278f9234f5493456e186d2aef06"
          }
        },
        "cc71df2d12cf4bd2be081ef8dacd7e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4216e661c2c74e2a9ccdf1ddc549c212": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe3698ecddb74af2be89eb3a4f2d11ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca75bf63422643e297cda65b4d239504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5eaa9c94a494c038fd92c316e304850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54c40278f9234f5493456e186d2aef06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "php_7g80Ph1f",
        "outputId": "ee555f0a-4e0f-4b56-80de-e1e92ee13d77"
      },
      "source": [
        "pip install textract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textract\n",
            "  Downloading textract-1.6.4.tar.gz (17 kB)\n",
            "Collecting argcomplete~=1.10.0\n",
            "  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting beautifulsoup4~=4.8.0\n",
            "  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Collecting docx2txt~=0.8\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "Collecting EbookLib==0.*\n",
            "  Downloading EbookLib-0.17.1.tar.gz (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 39.2 MB/s \n",
            "\u001b[?25hCollecting extract-msg<=0.29.*\n",
            "  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20191110\n",
            "  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting python-pptx~=0.6.18\n",
            "  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting six~=1.12.0\n",
            "  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting SpeechRecognition~=3.8.1\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 39 kB/s \n",
            "\u001b[?25hCollecting xlrd~=1.2.0\n",
            "  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from EbookLib==0.*->textract) (4.2.6)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Collecting soupsieve>=1.2\n",
            "  Downloading soupsieve-2.3-py3-none-any.whl (37 kB)\n",
            "Collecting compressed-rtf>=1.0.6\n",
            "  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n",
            "Collecting imapclient==2.1.0\n",
            "  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting ebcdic>=1.1.1\n",
            "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 50.1 MB/s \n",
            "\u001b[?25hCollecting tzlocal>=2.1\n",
            "  Downloading tzlocal-4.1-py3-none-any.whl (19 kB)\n",
            "Collecting olefile>=0.46\n",
            "  Downloading olefile-0.46.zip (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting pytz-deprecation-shim\n",
            "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting backports.zoneinfo\n",
            "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting tzdata\n",
            "  Downloading tzdata-2021.5-py2.py3-none-any.whl (339 kB)\n",
            "\u001b[K     |████████████████████████████████| 339 kB 44.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: textract, EbookLib, docx2txt, compressed-rtf, olefile, python-pptx\n",
            "  Building wheel for textract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textract: filename=textract-1.6.4-py3-none-any.whl size=22888 sha256=71416d0d38c3784e7f54fdf3b8cd6d5e1eaf51080e807f56c09a84f1e07aaa4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/75/40/78e8fff233a28dce67a9bf0ea2740ad3635dbca34e9b2af892\n",
            "  Building wheel for EbookLib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for EbookLib: filename=EbookLib-0.17.1-py3-none-any.whl size=38183 sha256=a78bbdefe2ba490da03f92cde2c52ec80d38ec06ca62b502b56cd4bb04c6ad1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/39/fd/db4f652431a55d28472ba7f5f7c9a8efad03b97f443a48ea2f\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=3755bcd124116c1c60805db162be33dedf69115720fcf9b9c44edf1268e261ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n",
            "  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6200 sha256=21ec771beb6740d81feafc4ccc661ec0d8ad4c47e0a76a8c8ce1f962ce801510\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=a247cafa6f9ae7bc1b5a6638d105d4f1aa1d3dcea07e9824962ee3d9be17fef3\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470950 sha256=cb3fa17b1999de1c7f1732a708c441661bdda4bbe209a20c7cab62155035ed1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n",
            "Successfully built textract EbookLib docx2txt compressed-rtf olefile python-pptx\n",
            "Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, soupsieve, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, EbookLib, docx2txt, beautifulsoup4, argcomplete, textract\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 1.5.1\n",
            "    Uninstalling tzlocal-1.5.1:\n",
            "      Successfully uninstalled tzlocal-1.5.1\n",
            "  Attempting uninstall: xlrd\n",
            "    Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: argcomplete\n",
            "    Found existing installation: argcomplete 1.12.3\n",
            "    Uninstalling argcomplete-1.12.3:\n",
            "      Successfully uninstalled argcomplete-1.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-python-client 1.12.8 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.26.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed EbookLib-0.17.1 SpeechRecognition-3.8.1 XlsxWriter-3.0.2 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.11.0 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 soupsieve-2.3 textract-1.6.4 tzdata-2021.5 tzlocal-4.1 xlrd-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwbBYi4s8y9T",
        "outputId": "938b9f1c-b753-4e76-e6bf-b777423db2bf"
      },
      "source": [
        "!pip install -q bert-extractive-summarizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ACwxf0b-oSY",
        "outputId": "c945a2d8-b354-45b0-e5ba-2c469282d464"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install transformers # > 4.0.0\n",
        "!pip install neuralcoref"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Collecting neuralcoref\n",
            "  Downloading neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n",
            "\u001b[K     |████████████████████████████████| 286 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.19.5-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.19.5)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.5.30)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (3.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.1.0->neuralcoref) (3.7.4.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.23.0,>=1.22.5\n",
            "  Downloading botocore-1.22.5-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1 MB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.23.0,>=1.22.5->boto3->neuralcoref) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.23.0,>=1.22.5->boto3->neuralcoref) (1.12.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, neuralcoref\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.12.0 which is incompatible.\n",
            "google-api-core 1.26.3 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.19.5 botocore-1.22.5 jmespath-0.10.0 neuralcoref-4.0 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFOQLIJF-08k",
        "outputId": "318a3b22-7ec4-493e-d6cb-926e48076448"
      },
      "source": [
        "pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0.tar.gz (777.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 777.1 MB 151 bytes/s \n",
            "\u001b[?25hCollecting spacy<3.2.0,>=3.1.0\n",
            "  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (21.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.62.3)\n",
            "Collecting thinc<8.1.0,>=8.0.9\n",
            "  Downloading thinc-8.0.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 38.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.19.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.7.4.3)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.25.11)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.1)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-3.1.0-py3-none-any.whl size=777079833 sha256=36ba2f95ca865f9be17f08cf0cad4e3b47d68755e7c2e42ec46c501a5548034a\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/2b/8f/6bd8c74cd6e6e6df1a6b1747be9815c35952837742247f459a\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy, en-core-web-lg\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 en-core-web-lg-3.1.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.1.3 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.12 typer-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "a433479dce9d4e3cac7458d66f2e18d8",
            "e28f237b49a048f784cf74eb2382bef8",
            "4ddee5da4cb24ddc9652d5cd98d22c8f",
            "7aab6fac1a324e848f369228ebe28ad8",
            "eeb57a4cb0c64498ae6063eb8a32cce6",
            "f58650cd9b8b48fe9fa061a7a976a40e",
            "cdc4609d508a4910a42bcf5c5bf42c84",
            "0e73908bfe0b46edb527e66192b10d6f",
            "c762938a472d4c18b614b6f04be1b072",
            "8f773841b0964cdeacad9ac07a893790",
            "94c9d93365ce4920b1bf0c6b8218a04a",
            "497994215bb24fd4a170f6ae2c217b32",
            "a50c40ca107a401293e7be06456dba43",
            "4b65cfb69b8342b3b28b7344eeeffc3a",
            "b272dd7f223c499db31c4c0743217f06",
            "bee1ec7dee384a268e4e06eac2d4f596",
            "9f23d0478268460f8123d1c432d1f7bb",
            "c3d4337e99da42618bcd6b4bbd34e535",
            "d194d1458ac24dfca5e9d1f70d8fb69b",
            "4de8d5d3be3447c1b1e5e7c89231dcea",
            "f4be4ebb4458439493c85bc118334ea1",
            "fc35df6370664c659d3add69c2675c95",
            "324b0f1c1c254d289b5a5d08c5787f81",
            "116b2ae2173e48aca10f4a4a338267da",
            "92497e45f1104776a744a2e096f15869",
            "b95b4a90e80642418e92373ea6b81989",
            "cf3310cdc3994ca284dcc3740b991733",
            "3ebe3fc679de4134919d6002cf6786da",
            "5810a4d538d846e09898eca8ab32555f",
            "0c780f0696f540f494b6ebec53a536aa",
            "fdcfb66518f34a63befd01bf9a11018f",
            "5588d0c00b254f569254cfb7daca6a34",
            "04d58a90a4b2425cbc453ac0fb4f2451",
            "3eee67378ca146db8437c5781624c9ee",
            "8ef92399ace44c4a9bbcd329675f3899",
            "077a834c5bcc4ec8875004d3a94773e2",
            "cf4609e8a79d4c968ff5bf4573c513ee",
            "00d5ff9ccefc40feb4f45cc931da9a2a",
            "d73a727ba4f1456d9cad79576cb35711",
            "1d2afbcbbe184c1fb369533eeb7937ae",
            "03a0041e28b84febb7d11d8f14e1af70",
            "eabfcc69aa00428dbad0c422c8d46471",
            "a1289c560ca0413a8adcbc3a86775b1d",
            "8d2939c5a35c4bf2b848842f3a1cfd95",
            "2f35eb19c90343718f49de6d8f325ec9",
            "20dd74cad67f49bd8b743e482e68fc3e",
            "1af2b3f06dda46fb90edc6600acaa3cb",
            "a2d638bb0cf34488bc0993c132d91f1d",
            "90c905ecb2db4ec1941f689be3f02896",
            "cc71df2d12cf4bd2be081ef8dacd7e2a",
            "4216e661c2c74e2a9ccdf1ddc549c212",
            "fe3698ecddb74af2be89eb3a4f2d11ab",
            "ca75bf63422643e297cda65b4d239504",
            "f5eaa9c94a494c038fd92c316e304850",
            "54c40278f9234f5493456e186d2aef06"
          ]
        },
        "id": "b6wYuDtI_EY0",
        "outputId": "f40a3842-fa59-4e27-edea-b63655d8cc32"
      },
      "source": [
        "from summarizer import Summarizer\n",
        "\n",
        "body = 'Text body that you want to summarize with BERT'\n",
        "body2 = 'Something else you want to summarize with BERT'\n",
        "model = Summarizer()\n",
        "model(body)\n",
        "model(body2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a433479dce9d4e3cac7458d66f2e18d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "497994215bb24fd4a170f6ae2c217b32",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "324b0f1c1c254d289b5a5d08c5787f81",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eee67378ca146db8437c5781624c9ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f35eb19c90343718f49de6d8f325ec9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Something else you want to summarize with BERT'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qENYC1nQAy0I",
        "outputId": "2f08ff60-079c-4702-c531-0c1a723394b4"
      },
      "source": [
        "from summarizer import Summarizer\n",
        "\n",
        "body = '''\n",
        "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price.\n",
        "The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal.\n",
        "Mubadala, an Abu Dhabi investment fund, purchased 90% of the building for $800 million in 2008.\n",
        "Real estate firm Tishman Speyer had owned the other 10%.\n",
        "The buyer is RFR Holding, a New York real estate company.\n",
        "Officials with Tishman and RFR did not immediately respond to a request for comments.\n",
        "It's unclear when the deal will close.\n",
        "The building sold fairly quickly after being publicly placed on the market only two months ago.\n",
        "The sale was handled by CBRE Group.\n",
        "The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building.\n",
        "The rent is rising from $7.75 million last year to $32.5 million this year to $41 million in 2028.\n",
        "Meantime, rents in the building itself are not rising nearly that fast.\n",
        "While the building is an iconic landmark in the New York skyline, it is competing against newer office towers with large floor-to-ceiling windows and all the modern amenities.\n",
        "Still the building is among the best known in the city, even to people who have never been to New York.\n",
        "It is famous for its triangle-shaped, vaulted windows worked into the stylized crown, along with its distinctive eagle gargoyles near the top.\n",
        "It has been featured prominently in many films, including Men in Black 3, Spider-Man, Armageddon, Two Weeks Notice and Independence Day.\n",
        "The previous sale took place just before the 2008 financial meltdown led to a plunge in real estate prices.\n",
        "Still there have been a number of high profile skyscrapers purchased for top dollar in recent years, including the Waldorf Astoria hotel, which Chinese firm Anbang Insurance purchased in 2016 for nearly $2 billion, and the Willis Tower in Chicago, which was formerly known as Sears Tower, once the world's tallest.\n",
        "Blackstone Group (BX) bought it for $1.3 billion 2015.\n",
        "The Chrysler Building was the headquarters of the American automaker until 1953, but it was named for and owned by Chrysler chief Walter Chrysler, not the company itself.\n",
        "Walter Chrysler had set out to build the tallest building in the world, a competition at that time with another Manhattan skyscraper under construction at 40 Wall Street at the south end of Manhattan. He kept secret the plans for the spire that would grace the top of the building, building it inside the structure and out of view of the public until 40 Wall Street was complete.\n",
        "Once the competitor could rise no higher, the spire of the Chrysler building was raised into view, giving it the title.\n",
        "'''\n",
        "\n",
        "#model = Summarizer()\n",
        "result = model(body, min_length=60)\n",
        "full = ''.join(result)\n",
        "print(full)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Chrysler Building, the famous art deco New York skyscraper, will be sold for a small fraction of its previous sales price. The deal, first reported by The Real Deal, was for $150 million, according to a source familiar with the deal. The building sold fairly quickly after being publicly placed on the market only two months ago. The incentive to sell the building at such a huge loss was due to the soaring rent the owners pay to Cooper Union, a New York college, for the land under the building.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7ilX1d0KoL6"
      },
      "source": [
        "def DataFromFile(path):\n",
        "  text = textract.process(path)\n",
        "  text = text.decode(\"utf-8\") \n",
        "  text=str(text).replace('\\n',' ')\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnaUCEk9QKSr",
        "outputId": "2c00b2dd-80b0-4518-a889-8fecd2e150d6"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "mypath='/content/sample_data/PDFs'\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(onlyfiles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['P12-3007.pdf', '2103.02252.pdf', '1.pdf', 'paper_74.pdf', 'D15-1097.pdf', 'book_of_proceedings.pdf', '1409.0473.pdf', '3.pdf', '1-s2.0-S1877050917321774-main.pdf', 'E17-1088.pdf', 'allen19a.pdf', '5.pdf', '4211-8501-1-SM.pdf', '6.pdf', '20171231 Lexical normalization of roman Urdu text.pdf', 'D08-1014.pdf', '1-s2.0-S2405844018356688-main.pdf', '1405.5447.pdf', '4.pdf', '1707.09920.pdf', '1902.01313.pdf', 'futureinternet-11-00022.pdf', '2.pdf', 'W09-3406.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3SdyMgasNVR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49DyaAd0TNka"
      },
      "source": [
        "import textract\n",
        "appender=[]\n",
        "for docpath in onlyfiles:\n",
        "  appender.append(DataFromFile(mypath+'/'+docpath))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osPZGIi7UtxJ",
        "outputId": "061d5b8b-57fc-46d9-8c47-30e1adcff5d9"
      },
      "source": [
        "len(appender)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZiwQd_qVEHI"
      },
      "source": [
        "summarized=[]\n",
        "for val in appender:\n",
        "  full=''\n",
        "  result = model(val, min_length=30,num_sentences=12)\n",
        "  full = ''.join(result)\n",
        "  summarized.append(full)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku3j_IqjYiMI",
        "outputId": "6c23892d-02e1-469d-a66b-7098d2eaeda0"
      },
      "source": [
        "len(summarized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NRB2_ELNbi4k",
        "outputId": "bf986307-f43a-4ba4-dc32-89d66b7cce85"
      },
      "source": [
        "appender[13]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Received September 30, 2020, accepted October 12, 2020, date of publication October 15, 2020, date of current version October 28, 2020.  Digital Object Identifier 10.1109/ACCESS.2020.3031393  RUTUT: Roman Urdu to Urdu Translator Based on Character Substitution Rules and Unicode Mapping  MOBEEN SHAHROZ 1, MUHAMMAD FAHEEM MUSHTAQ 2, ARIF MEHMOOD 3, SALEEM ULLAH 1, AND GYU SANG CHOI 4, (Member, IEEE) 1Department of Computer Science, Khwaja Fareed University of Engineering and Information Technology, Punjab 64200, Pakistan 2Department of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Punjab 64200, Pakistan 3Department of Information Technology, The Islamia University of Bahawalpur, Punjab 63100, Pakistan 4Department of Information and Communication Engineering, Yeungnam University, Gyeongsan 38542, South Korea Corresponding authors: Gyu Sang Choi (castchoi@ynu.ac.kr) and Arif Mehmood (arifnhmp@gmail.com)  This work was supported in part by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2019R1A2C1006159) and in part by the Ministry of Science and ICT (MSIT), South Korea, under the Information Technology Research Center (ITRC) support program (IITP-2020-2016-0-00313) supervised by the Institute for Information & communications Technology Promotion (IITP).  ABSTRACT Urdu language written in English alphabets for communication is known as Roman Urdu. In pronunciation, both are the same but different in spelling and have different shapes of the alphabet. A survey acknowledges that 300 million people are speaking Urdu and about 11 million speakers in Pakistan from which maximum users prefer Roman Urdu for the textual communication. Today most of the modern technologies like computers and mobile phones using English script, due to this local Urdu user has to use English letters to type Urdu script that is Roman Urdu. In this research, Roman Urdu to Urdu Translator (RUTUT) is proposed that consists of preprocessing methods, rule-based character substitution and Unicode based character mapping techniques. It can transliterate the messages or descriptions from the Roman Urdu script to Urdu script which may help the Urdu speaker to elaborate their message in efﬁcient manners. The focus of this research is to analyze the issues related to the Roman Urdu script to Urdu script transliteration and develop a translator based on the concepts of transliteration. This research analyzed Roman Urdu data and identiﬁed different rules-based character substitution techniques that transform the Roman Urdu into Urdu script at fundamental levels. This research is carried out using a python programming language in programming tool Anaconda in Jupiter notebook and user-friendly Graphical User Interface (GUI) created by using Tkinter library. To evaluate the RUTUT, different translational tests are performed and compare those results with famous Google online translator and ijunoon online transliteration. The analyses of results show that the proposed RUTUT approach translates accurately than Google online translator and ijunoon online transliteration.  INDEX TERMS Roman Urdu, transliteration, rule-based approach, character substitution, unicode mapping.  I. INTRODUCTION The multi-linguistic content rapidly growing on the internet in the last decade. The information retrieval process based on cross-lingual [1] and monolingual gain a lot of atten- tion from the Natural Language Processing (NLP) researcher community World Wide Web (WWW). It was the web of the English language and then become a huge collection of  The associate editor coordinating the review of this manuscript and  approving it for publication was Yilun Shang  .  multi-linguistics. When the information retrieval process con- centrated on the queries and accessed information in the same language is known as monolingual and cross-lingual focused to access information in several different languages [2]. Some Indo-Aryan languages gain attention from researchers in recent years and Urdu started to get focus because on the web Urdu is a major part of the Asian languages [3].  The researchers of the NLP attract to those languages that have script writing styles from right to left like Urdu and Arabic. Urdu is the national language of Pakistan. There  VOLUME 8, 2020  This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/  189823  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  are almost 11 million Urdu speakers in Pakistan and more than 300 million in the world [4]. Majority of Urdu speakers present in Pakistan, India, UK, Canada and USA. The foun- dation of Urdu is lies in Arabic, Persian and most of the South Asian languages. Especially Arabic has been studied deeply and it’s also one of the Semitic languages. Punjabi, Pashto, Dari and Farsi (Persian) also follow the right to the left script writing style. These languages belong to Proto Indo-Iranian languages [5] that are widely spoken in regions of South Asia. Free word order characteristic and lack of capital and small words are some terms of similarities in these languages. So, many similarities are found in the writing and speaking styles of these languages but individually each language has its grammar and semantics [6]. Due to this, each language needs separate attention. The syntax and morphological structure of Urdu is consisting of Persian, Sanskrit, English, Turkish and Arabic [7]. That’s why its structure is complex than other languages. Urdu language processing in the reserved state because of the availability of fewer linguistic resources and gets less attention from the language engineering community. The digital electronic media and the internet are growing very rapidly [8]. Data mining [9] and Information retrieval [10] processes are engaged to analyze and maintain the vast amount of data. In this age of technology, all the languages are fully functional in computer devices but almost every machine or computer device using English language stan- dards to write or type messages. The local users of mobile devices are largely using Roman Urdu [11]. When a local user who does not know any basics of English language or English alphabet then how the user understands the message or any social media data that is in Roman Urdu as discussed in the section II. Communication provides the link to every process and leads the way to success. The Roman Urdu and English make computer devices and digital worlds very difﬁcult. When the user uses those devices in the Urdu language then everything will get easy to understand for Urdu speaker.  Data mining tasks and information retrieval that mostly consists of topic modeling, event extraction, decision mak- ing, relationship exploration, sentiment analysis gives a deep analysis of NLP. There are some important techniques like stopwords [12] removal, name entity recognition [6], shallow parsing, tokenization, POS tagging [13] and morphologi- cal analysis [14] are the major parts of the NLP system. English NLP systems are mature enough but Urdu and Roman Urdu NLP need more concentration [7], [15], [16]. Many researchers wrote survey papers on Urdu and its related issues. Many others perform different tasks like stopwords identiﬁcation, stemming [17], concept searching and NER but not try to give any rule or standard that translates the Roman Urdu into Urdu script [4], [18].  Roman Urdu is the non-standard language that has not any type of grammar or standards of spelling for the written script. Roman Urdu to Urdu script translation has been done in this research. The Urdu speaker who does not know how to type or write in the English language and what is the meaning of English letters than it is very difﬁcult for the  user to understand Roman Urdu. The RUTUT translator is based on three major modules that preprocessing, rules-based character substitution and Unicode based character mapping. These modules are further divided into sub-components or modules that work together and perform the speciﬁc oper- ations to translate the Roman Urdu query. The proposed architecture and the rule-based character substitution that consists of 12 rules are the novelty of the proposed research. When a Roman Urdu query gives to the RUTUT translator as input then this query pass through these three modules. Each module applies its functionality and passes it to the next module. In the end, local users can get a proper Urdu script as shown in Figures 1 and 3.  The contribution of this paper is as follows. • The translation of the Roman Urdu script to Urdu script  by Using RUTUT translator.  • The preprocessing ﬁlters unnecessary data to make it  more effective for further processing.  • The rule-based character substitution depends on rules that convert the Roman Urdu script into a speciﬁc form of Roman Urdu.  • The Unicode based character mapping convert  the Roman Urdu into Urdu characters by following the design scheme of mapping based on Unicode.  • The performance analyses and comparative analyses  evaluated the performance of the RUTUT translator.  The structure of the paper categorised into the following sections: section II presents the Roman Urdu in which the impact and inﬂuences of the Roman Urdu language is dis- cussed. Section III explains the related work regarding the efforts of previous researcher and studies that are relevant to the proposed approach. Section IV presents the mate- rial and methods of this research. Section V explains the results and discussion based on the proposed methodology. Section VI proposed the comparison of the existing and pro- posed research. Section VII presents the conclusion of this research.  II. ROMAN URDU Urdu and English languages are widely used in South Asia for textual communication. Digital media such as WhatsApp, Facebook and SMS [11], etc. are largely used by Roman Urdu users for communication with no standard spelling rules. Roman Urdu developed like ‘‘necessity is the mother of invention’’ and also by the great impact of the electronic and digital media. Practically, all the ofﬁcial documents and Gov- ernment departments are all drafted documents in the English language [15], [19]. It is crowned as the global business lan- guage. The English language contains such supreme impor- tance in the global age. Consequently, it is a great need to translate the Roman Urdu language into English. Urdu is the supreme language in Asia for composing research, literature and poetry [4]. Poets manipulated the meaning and polite- ness of Urdu words in multi-levels from centuries to cre- ate memorable verses in beautiful manners. So related facts illustrate the inﬂuence of Urdu to English Transliteration.  189824  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 1. The Graphical Abstract of the proposed RUTUT Translator.  FIGURE 2. Local users need to use Roman Urdu in daily life.  The Pakistani people prefer the Urdu language in the form of Roman Urdu to write poetry, literature and verses. A survey performed in [20] was to illustrate the facts that 80% of Pakistani people use Roman Urdu.  When the user feels uncomfortable in using their mother language then they try to use some English letters for the communication like typing message on SMS or WhatsApp, writing comments on Facebook posts and in the reviews of products etc to elaborate the thoughts in mother language as shown in Figure 2. When writing Urdu language using the Roman script (English letters) then it is known as Roman Urdu. An example is given in Figure 3.  Mobile phone communication was largely used in South Asia by local users, to organize events, maintain social  FIGURE 3. A sentence in the form of Roman Urdu, Urdu, and English Languages.  relationships and expressing emotions. Roman Urdu is widely used in text messages for communication. The research is carried out to analyze the structural and linguistic properties of various communication media [21]. Most of the research that relates to mobile data has been carried out on data from developed countries. For text predictions, spelling analyses and spam identiﬁcation, etc. tasks of linguistic research that was targeting text message written in European languages.  VOLUME 8, 2020  189825  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  III. RELATED WORK Many researchers and studies belong to Urdu transliteration [22], [23], Urdu stemming method [20], [24], [25], POS tagging methods [26], sentiment analysis [27], lexical [28] and morphological analysis that gives information of lin- guistic translation and evolves the Urdu language, are all reviewed in this study. NLP frameworks mature enough for the English language [22] but Urdu NLP framework needs a lot of effort and research to make it mature. Data mining tasks and computational linguistics that depend on the morpho- logical analysis, information extraction, sentiment analysis, part of speech tagging and topic modeling are the methods of NLP. The NLP in the speech and language processing domain [29] contributes to the cognitive modeling, machine translation learning phrases, tera-scale language models, neu- ral networks multi-task, incremental processing and language resource retrieval are the critical signiﬁcant.  Transliteration algorithms [43], [44] and word dictionaries [45], [46] are used to convert the Roman form of Urdu to Urdu script but accuracy is greatly reduced because of the presence of English words with Roman Urdu in conversational use. Soundex algorithm [47] is used to solve conversational issues that assigns the code to English words on the bases of the position that are then mapped to Urdu script [48]. A lot of efforts and attempts are made in the manual analysis of words for the accent localization. 1736 distinct words are translated into English successfully out of 2000 which shows the accuracy is 86% [49]. Neural machine translation model is based on encoder-decoder architecture [32] using sequence to sequence learning methods. This model consists of two parts one takes the input sentence and the second is responsible for the output. This input is in Roman Urdu form. After getting the input sentence distributes the representation of the source language based on the encoding-decoding architecture that starts the network and riches to the learning dependencies. Then the neural machine translation model translates the Roman Urdu to Urdu script. BLEU [50] evaluation metric is used that is 48.6 on the test.  Roman Urdu to Urdu translation based on the word list [23] gives the novel transliteration approach to the Persio-Arabic letters that have the same in sound but different in written form in Urdu script. The rule-based system used consists of uni-code mapping. This study also identiﬁes the issues involved in translation and different ways of Roman Urdu to Urdu translation. One of the complex issues that han- dled was one to one mapping is not enough. Emerging new machine and language translation techniques that contribute to a large scale provides the Neural Language Processing and computational linguistics to solve communication problems [26]. The presented approach was consists of three stages. Knowledge-based corpus with its tag set used for tokeniza- tion, grammatical rule-based Urdu POS-tagger that presents the syntactical structure and prepared the grammatical struc- ture of sentences for Roman Urdu to English translation. As compared to the Google translator proposed approach in this study gives better results.  The neural network based on the sequence to sequence network model [32], [36], [51] has become a very successful and popular technique to predict the identical sequence for mapping purposes. The kind of problems like handwriting generation, conversational modeling, the secondary structure of protein prediction, question answering, text to speech, music, [52] modeling of polyphonic music, speech recogni- tion, machine translation and modeling of the speech signals are solved by applying these neural network-based mod- els. Further, these concepts of sequence to sequence model based on neural networks are comparatively new but also need relative enhancements. The bidirectional models of [35] include encoder and decoder techniques that take credit for both right to left and left to right orders of sequences. Some improvements in encoder-decoder based modeling but still get only right to left manners [53]. The letter sequence-based character modeling [54] feed the encoders that will create sentences, not with the words but with a sequence of letters. Attention-based models [55] distinguish themselves by draw- ing toward the center with the appropriate character of the input to the decoder by applying the soft concept of attention. Transliteration is the subcategory of linguistic translation such that changes of the alphabetic letters of one language into another language is done in transliteration based on similarity measures of the soundings of characters of the target language. Especially, sequence to sequence character mapping technique is mostly implemented in the tasks of the machine learning-based transliteration. The transliteration method has been proposed for linguistics [56] of Sanskrit that translates it into English. Furthermore, the attention-based machine learning approach is utilized to translates the English language into Persian. The most important and challenging part of linguistic engineering and transliteration operations is to identify the semantics, syntax and morphology of the target and source languages. There can be problems of misalign- ment among the sentences of the source language and the sentences of the target language as well as the length of both languages. In other words, both languages are completely different in every aspect.  Urdu is a morphologically deep complex language but also has some deﬁciencies and low resources as mentioned by [25]. NLP of the Urdu language statistical method is mention in [57]. Convolutional Neural Network (CNN) based sequence to sequence character mapping techniques, phrased based statistical models of machine learning and conventional techniques based on NLP techniques are used for linguistic translational purposes. Some of fundamental concepts of the translational techniques are based on POS tagging [25], [33], stemming [20], [25], tokenization, lemmatization, annota- tion [58], named entity recognition and sentence boundary detection [25] are implemented in the different ﬁelds. These ﬁelds are sentiment analysis, opinion mining, handwriting recognition and detection of plagiarism. The work accom- plished for the Urdu language has massively depended on conventional NLP based language handling methods [58], [59] and the utilization of deep learning methods to ﬁguring  189826  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  TABLE 1. Comparison of the existing systems.  out how to address the issue of machine interpretation in the Urdu language is still in its beginning. Large datasets are a basic necessity for deep learning strategies to work and successfully modeled the assorted variety and catch the intrinsic unpredictability of language. The accessibility of the parallel corpora opens many ways for additional research for deep learning-based machine translation and transliteration of different linguistics. For example, [60] gives an equal cor- pus in 11 dialects including Dutch, English, Spanish, Swedish and Italian to give some examples. A parallel corpus for an enormous scope in the Urdu language is a road unexplored. Nonattendance of Roman-Urdu to Urdu Parallel is a bottle- neck in investigating further exploration openings in the area of transliteration just as interpretation. CLE Pakistan [61]  acquired a dataset of 100K Urdu words from education, health, business and training like different related areas. This is consists of two categories. One is imaginative and the other is informative with 20% and 80% ratio [62]. A large dataset created that contains 512,000 spoken words and 1,640,000 text words of Urdu. [63] has been done an incredible job by creating an Arabic Urdu script dataset contains Unicode characters and an XML format.  IV. MATERIAL AND METHODS Transliteration is the method of transforming one language (Roman Urdu) into the target language (Urdu language) according to the exact pronunciation instead of focusing on meaning. It is a difﬁcult task to develop a translator for the  VOLUME 8, 2020  189827  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 4. Architecture of the RUTUT: Rules-based character substitution and Unicode character mapping based Roman Urdu to Urdu Script Translator.  Roman Urdu language because it is not a standard language and does not have any proper rule of grammar or any writing vocabulary rules. A survey study [21] on mobile text data gives very interesting results that consist of the collection of 116 users and 346,455 mobile text messages. These results illustrate that a single word was typed by a single user with different spellings in different messages and also shows user try to complete the conversation in minimum words like using short forms. In this study, the main focus of the proposed approach is to develop a rule-based transliteration model for Roman Urdu that is the novelty which gives the proper stan- dard to Roman Urdu. This section consists of the proposed methodology and methods that are used in this research to achieve its aims.  A. MAIN FRAME OF RUTUT The proposed methodology is consists of three components such as preprocessing, rules-based character substitution and Unicode based character mapping shown in Figure 4. After initiating the RUTUT translator user can use user-friendly interface that depends on one input box, one output box and a translation button. When a user enters a Roman Urdu script as input then ﬁrst pass this input to the ﬁrst component  preprocessing that ﬁlters the unnecessary data. After this, the preprocessed Roman Urdu script pass to the next component rule-based character substitution that consists of 12 different rules to convert any form of Roman Urdu into a speciﬁc form. The last component is the Unicode conversion that trans- forms the Roman Urdu characters into the Urdu as shown in Figure 17. After character by character Unicode mapping, the Roman Urdu completely transform into an Urdu script then this Urdu script can easily be used by the user. By using the proposed RUTUT translator the user can easily understand the exact meaning of the Roman Urdu script and can com- municate to the other Roman Urdu user more expressively.  The RUTUT translator is developed for this research by using a Python programming language [64] in Anaconda platform in Jupiter notebook [65] and Tkinter library [66] is used to design Graphical User Interface (GUI) that makes it easy to use and user friendly.  B. PREPROCESSING Roman Urdu text is in raw form, which needs to preprocessed. Reshaping of raw data by using data preprocessing methods [67], [68] is one of the data mining techniques. Transla- tional models can learn from preprocessed data efﬁciently.  189828  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  TABLE 2. Roman Urdu letters or sequences equivalent to Urdu vowels.  Real-world Roman Urdu data is incomplete, inconsistent, or missing in certain behaviors or trends, and is in all like- lihood to incorporate many errors. Data preprocessing is an established approach to resolving such problems. In the world, the incompleteness of data is a general thing, lacking attribute values, errors, and outliers or containing only aggre- gate data. In preprocessing, ﬁrstly perform tokenization [69], [70] is the act of breaking up a sequence of strings into pieces such as words, keywords, phrases, symbols and other ele- ments called tokens. Tokens can be individual words, phrases or even whole sentences. The word tokenization is applying to split the documents or sentences into individual terms that is helpful in ﬁltering non-important words and punctuation. Second, in the case of sensitive system, capital case letter and lower case letter consider as different terms because of this conversion of capital case letters into lower case, reduce the unique terms in the documents. This increases the efﬁciency of the feature extraction process. Third, the process of changing statistics to something, a system can understand referred to as preprocessing.  C. RULE BASED CHARACTER SUBSTITUTION Roman Urdu is not the standard language that has not any grammar rules and speciﬁc spelling or writing standards. That’s why these rules are developed in this study which is the novelty. The Roman Urdu users use different spellings of a similar word in different messages. These rules transform the randomly spelt Roman Urdu script into one speciﬁc form that helps in further processing. Every step has its own impor- tance. When preprocessed Roman Urdu as an input pass to the rule-based character substitution phase then it goes through the following steps:  1) RULE 1: CONVERSION OF THE VOWEL CASE The preprocessed Roman Urdu needs to convert all the con- sonant letters into capital cases except ‘y’, ‘h’ and vowels (‘a’, ‘e’, ‘i’, ‘o’,‘u’). This mapping is applied to consonants only because vowels are very complex in one to one replace- ment processing. The preprocessing applied ﬁrst that helps in mapping properly if any vowel letter accidentally remains capital then rules are not applied to this letter.  2) RULE 2: REMOVAL OF CONSEQUENT LETTERS When all consonants become capital then some of the let- ters are consequently repeated in a capital case. Remove this duplication of letters from the capital case consonants  FIGURE 5. Impact of ‘ain’ and ‘alif’.  FIGURE 6. Impact of ‘alif-mad’ and ‘ain’.  because of the germination of consonant letters written only once in Urdu. In the Urdu language, tashdeed is used as germination marks. Like ‘ullo’(owl) in Urdu has a diacritical tashdeed sign because ‘laam’ is repeated but it was written once. In Roman Urdu ‘ullo’ has double ‘l’. Same ‘bud- dho’(stupid) has tashdeed sign on consonant ‘daal’. It comes only once in the Urdu language with tashdeed but has double ‘d’ in ‘buddho’ in Roman Urdu. That’s why to remove dupli- cation of consequently capital letters because Urdu does not has any double letters. Roman Urdu has so many words that contain double letters but not in Urdu script.  3) RULE 3: INCLUSION OF LETTERS The letter ‘A’ is included at the start of the word if any vowel letter found in the beginning. A vowel in Urdu script cannot occur at the start of the words without having before ‘alif’, ‘ain’, or ‘hamza’. Mostly ‘ain’ and ‘alif’ occurs at the start of the word like ‘adal’ and ‘alag’ both have vowel letter ‘a’ in Roman Urdu that is equivalent to diacritic mark ‘zabar’ in Urdu as shown in Figure 5.  In the start of the vowels sequence ‘aa’ of the Roman Urdu word act as Urdu alif-mad that is equivalent to two consec- utive Urdu ‘alif’ letters. The sequence ‘aa’ is equivalent to alif-mad or ain-alif like ‘aam’ target two Urdu script words as shown in Figure 6. A Roman Urdu word ‘aur’ has a sequence of vowels ‘au’ at the start. Table 2 shows that sequence ‘au’ equivalent to the Urdu word ‘vao’. ‘alif’ written before ‘vao’ in Urdu script word ‘aur’ that shows the vowel rule at the start of the word is not applicable for ‘a’ vowel sound only.  4) RULE 4: REPLACE ‘eh’ AND ‘oh’ The replacements that occur for the longest sequence from the left-hand side are as shown in Figure 7. An issue found in the transliteration of Roman Urdu to Urdu script was the vowel changed around Urdu ‘gol-hay’. An example of the Roman Urdu word ‘sheher’(city) shows that Urdu vowel ‘zabar’ present in between Urdu ‘sheen’ and Urdu ‘gol-hay’ and Urdu ‘rey’. In pronunciation vowel ‘e’ places instead of ‘a’.  VOLUME 8, 2020  189829  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 9. Substitution of ‘ai’ effects in Urdu words.  FIGURE 7. Substitution of ‘oh’ and ‘eh’ by capitalizing the ‘h’.  FIGURE 10. Substitution of ‘eh’ and ‘ay’ by capitalizing ‘y’.  FIGURE 8. Substitution of ‘eh’ and ‘ay’.  Similarly, a Roman Urdu word pronounces ‘shohrat’(fame) has the Urdu vowel ‘pesh’ after ‘sheen’ instead of ‘shuhrat’. This rule deals with vowels around ‘gol-hay’.  • ehe = H, eHe • oh = H, oH • eh = H, eH • h = H  5) RULE 5: REPLACE ‘ey’ AND ‘ay’ INTO ‘Y’ AND ‘E’ Replace the ‘ey’ with ‘Y’ and ‘ay’ with ‘E’ if those are the last sequence of the Roman word that replacement is shown in Figure 8. If ‘Y’ found in the medial position of the Roman Urdu word then it is replaced by ‘choti-ye’ in Urdu script but it is replaced with Urdu ‘bari-ye’ if it is at the ﬁnal position of the word. ‘bari-ye’ and ‘choti-ye’ produce different sounds when both are used as vowels. Roman Urdu word ‘hain’ contains an ‘ai’ vowel sequence in the middle of a word that sounds ‘choti-ye’ in Urdu. In the case of Roman Urdu word ‘hai’ contains the same sequence at the end of the word that sounds ‘bari-ye’ in the Urdu language as shown in Figure 9.  6) RULE 6: REPLACE ‘ey’ AND ‘ay’ TO ‘Y’ AND ‘Y’ After rule 6 it also needs to replace the remaining ‘ey’ and ‘ay’ with ‘Y’ if ‘y’ is preceded with ‘e’ and ‘a’. Figure 10 presents the replacements. ‘y’ acts as a consonant as well as a part of the vowel sequence.  FIGURE 11. Substitution of ‘ei’ and ‘ai’.  7) RULE 7: CONVERSION OF ‘y’ Convert the remaining ‘y’ into the capital case. All special cases of ‘y’ already handled in previously deﬁned rules. Now, this replacement is generally placed to handle the remaining ‘y’.  8) RULE 8: CONVERSION OF ‘ai’ AND ‘ei’ if the vowel sequence ‘ai’ and ‘ei’ present at the end of the word then done the following replacements shown in Figure 11. Roman vowels character are considered as a spe- cial case of syllable boundary when it appears in a sequence. Syllable boundaries cannot be predicted in Urdu and not in Roman Urdu script. If consonants appear before vowels in the syllable then general rules are enough to translate it but if vowels appear in the start then Rule IV-C3 applies to it. Table 2 shows the Roman script that a single Urdu vowel character can be a map on a single Roman Urdu character or two-character sequence. A sequence of Roman Urdu char- acters can be considered as equivalent to one or two Urdu vowels. The ‘ai’ is the two vowel sequence corresponding to a single letter in Urdu ‘bari-ye’ or belongs to two different syllables. The start of the second syllable is ‘i’ and ‘a’ belongs to the ﬁrst syllable. ‘A’ and ‘Y’ are introduced in the repre- sentation of Urdu ‘hamza’ and ‘ain’ because these are needed before the vowels.  189830  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 12. Substitute ‘A’ and ‘Y’ in between the vowels.  9) RULE 9: HANDLING VOWEL COMBINATION Find all the combinations of vowels character sequence if found any sequence of two or more vowels and place A for (ain) and Y for (hamza) in between them. This is the generalized form of Rule IV-C8 that deals with all possi- ble interpretations of the vowel sequence. As the example shown in Table 2 and Figure 11 ‘a-i’ and ‘ai’ has two vowel combinations of the ‘ai’ vowel sequence. Then for further processing ‘aAi’, ‘aYi’ and ‘ai’ are generated. In another vowel sequence ‘ua’ has only a ‘u-a’ combination. This does not map on any single Urdu vowel. That’s why another com- bination is not valid and ‘uYa’ and ‘uAa’ are generated for the next processing. In vowel sequence ‘aai’(she came) has three combinations ‘aa-i’, ‘a-ai’ and ‘a-a-i’. ‘aAai’, ‘aaAi’, ‘aYai’, ‘aAaAi’, ‘aaYi’, ‘aYaYi’, ‘aAaYi’, and ‘aYaAi’ combinations are generated for further processing after applying this rule.  10) RULE 10: CONVERSION OF TWO VOWEL COMBINATION It is generally a one to one character mapping rule that deﬁnes the way of encoding against vowel sequences in the Roman Urdu script. The encoding scheme of the Roman Urdu vowel sequences shown in Figure 13.  11) RULE 11: SUBSTITUTE THE VOWELS AT THE FINAL POSITION Search the given below vowels at the end of the Roman Urdu words and perform the following substitution.  Word’s last character has always a long vowel in Urdu scripts like in Roman Urdu word ‘aadmi’(man) ‘i’ present at the ﬁnal position that is not ambiguous between the long vowel (choti- ye) and short vowel (zer). Roman Urdu ‘sada’(simple) ‘a’ at the ﬁnal position but in Urdu script ‘a’ is substituted with ‘gol-hay’.  12) RULE 12: GENERALIZED CONVERSION OF VOWELS Replace the remaining vowels as given below. The general- ized form of the rule comes forward after all the special rules. This is the last rule of the rule-based character mapping.  • e = E • i = Y • a = A, H • u = O  • a = A, null • e = E • i = Y, null • o = O • u = O, null  VOLUME 8, 2020  FIGURE 13. Presenting replacements of vowels sequence with capital letters.  D. URDU UNICODES The Urdu language is inscribed in calligraphic Nastaliq script that has 39 to 40 unique letters. Simply, the Urdu translates into the Latin alphabets then it is known as Roman Urdu that eliminates many linguistic pronunciation elements that are not found in any equivalent in the English language but in Latin script or other languages are used them in writing. The Persio-Arabic script in the modiﬁed form is named Urdu script. These are close to the phase of the Nastaliq style of Perso-Arabic script development. In 1911, the Urdu typewriter invented then Urdu newspapers start publishing the handwritten scripts by katibs or khush navees (calligra- phers) until the 1980s. The Daily Jang was the ﬁrst Pakistani national newspaper that composed and published the news- paper on the bases of computer-based Nastaliq. There are so many efforts underway that focus on the development of the more user-friendly and sophisticated Urdu linguistic support system on the internet and computers. In this modern age, nearly all Urdu the journals, magazines, periodicals and Urdu newspapers are all composed in the computer by using Urdu phonetic based software.  1) UNICODE The Unicode based communication is the general standard of character encoding pattern utilized for the describing text for machine processing. It gives further knowledge about the characters and their application. It presents uniform methods of encoding and decoding the multi-linguistic textual data and brings order to the phase of operations that made it  189831  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 14. Unicode chart on the bases of character mapping rules.  hard to trade text data globally. Researchers who deal with multi-linguistic scripts in the Urdu language in the computer system like in business, researchers, scientists and linguists others also discover that it makes their work simple. The scheme of Unicode is based on the ﬂexibility and simplicity of ASCII but goes considerably ahead from ASCII’s insufﬁ- cient capability to encode only signiﬁcant Latin script.  All written languages of the world can be efﬁciently encoded in Unicode standard’s capabilities. It assigns the numerical value and name to each character that makes it simple and efﬁcient for linguistic processing. Three encod- ing forms supported by the Unicode standards are UTF-8, UTF-16 and UTF-32 that have a common repository of char- acters. Those encoding methods support for encoding mil- lions of characters. This is enough for all associated character encoding conditions, including full coverage of all historic scripts of the world and also for common notational affairs. The Unicode standard speciﬁes codes for characters prac- ticed in all the inﬂuential kinds of literature written today. The scripts cover the Middle Eastern right-to-left scripts, European alphabetic scripts, and many other scripts of Asia. More than 135,000 characters codes present by the Unicode standard from the world’s alphabets, collections of symbols and writing systems. Unicode considers the purpose of giving a code point (a number) that is unique for each character in text processing, not a symbol for each character. In another way, Unicode describes characters in an abstract form and gives the visual rendering (style, shape, size or font) to the machine program or software like the web browser or word processor. The simple aim of the Unicode designers becomes complex when concessions are made in the hope of pro- moting the Unicode system rapidly. The Unicode chart is  FIGURE 15. Mapping sequence of Roman Urdu to Urdu character.  shown in Figure 14 which represents the Unicode for the characters of the Urdu script. These Unicode are used in this study to encode or map the Roman Urdu characters to Urdu characters.  2) CHARACTER MAPPING Today computer generation needs to understand the Roman Urdu or any other language. when it was about the machine or computer then it became necessary that computers can understand every single word or character properly. The com- puter does not recognize the shape or character of the lan- guage. Every language has its style and shape of the alphabet that makes it difﬁcult to understand. The computer machine working on the bases of the codes (are numerical values) that can easily understandable for the computer. With the rapid growth of the internet and digital media, it became necessary to develop a system of codes for languages or codes for each style or shape of the character. Then the Unicodes system developed to recognize the language alphabets for the computer [71], [72].  In the proposed RUTUT approach, the scheme of character mapping is shown in Figure 15. Previous section IV-C dis- cussed issues in the translation of Roman Urdu to Urdu and its solution. By analyzing those issues develop this scheme of Unicodes for the Urdu alphabets. Character mapping is the phase in which a preprocessed and rule-based substitutions are applied to Roman Urdu and a form of Roman Urdu is  189832  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  obtained. After those phases, this Roman Urdu form needs to translate into the Urdu Language. For this purpose, the Unicode list used to substitute Roman Urdu with Urdu script. The Unicode based character map shown in Figure 14 and scheme of substitution is shown in Figure 15. When all of the character mapping rules and substitution into Urdu script using Unicode are applied on the input (Roman Urdu) script then the Urdu form comes as an output. The computer system translates the Roman Urdu character alphabet by alphabet into Urdu Unicodes that presents as Urdu script as an output.  V. RESULTS AND DISCUSSION In this research, Roman Urdu to Urdu script transla- tional (RUTUT) model is developed as shown in Figure 19 consists of rule-based character substitution and Unicode based character mapping techniques. Those are fundamental techniques to translates one language into another. Every language has its own grammar, spelling standards and rules to write but Roman Urdu is not the standard language. Roman Urdu language has not a speciﬁc rule to spell words. When the user write one word in different spellings with different capitalizations in words then it is a difﬁcult task to recog- nize the pattern of the words. This is a very necessary task to recognize the fundamental patterns in any language that gives it a proper meaning. By analyzing different issues in translating the Roman Urdu, this research solves those issues one by one as discussed in section IV-C. As solution to those issues rules are building up one by one which gives the pattern of the words of Roman Urdu structures.  for sentences in input do  Algorithm 1 RUTUT 1: System Initialization 2: procedure Mainframe(input) 3: 4: 5: 6: 7:  ﬁlter = Call Preprocessing(sentences) for Words in filter do Substitution = Call CSR(Words) SubSent = appending romanized substituted  words.  8: 9: 10:  11:  12:  Return Output  for Words in SubSent do  TranslatedWords = Call UCM(Words) TranslatedSent = append TranslatedWords Output = Appending translated sentences  A. RESULTS The focus of this research is to propose the fundamental rules that will help to transliterate Roman Urdu into Urdu script as well as gives the standard rules to evolve the Roman Urdu. In this section, RUTUT translator evaluation is presented in different ways and comparing it with two different translators. The proposed model RUTUT translator’s structure is consists of three phases which present how the RUTUT structure  FIGURE 16. Step by Step Roman Urdu Word Translate into Urdu Words.  converts the Roman Urdu into Urdu script. Gives outstanding results that are discussed in upcoming sections.  B. RESULTS OF PROPOSED MODEL RUTUT TRANSLATOR RUTUT translator consists of three phases that present the step by step results in Figure 16. Phase 1 consists of two modules such as preprocessing and rule-based character sub- stitution technique. A Roman Urdu script enters as an input to the ﬁrst phase in its raw form that contains impurities which can reduce the accuracy of the transliteration results. There are also speciﬁc steps such as capital to lower case conversion, remove the special symbol, removal of numbers, sentence tokenization and word tokenization are performed as shown in Figure 4. In the second module, rule-based character substitution applied on that ﬁltered form of the preprocessing phase as shown in Figure 16. This module consists of 12 basic rules which substitute character against character. After applying these steps of two modules a ﬁltered Romanized form comes as an output.  The output of the phase ﬁrst becomes an input of the second phase. Then the Unicode based character mapping scheme is designed in this phase. This scheme of mapping is based on Unicode that is the four digit code. By using this code of scheme each character of Roman Urdu mapped  VOLUME 8, 2020  189833  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 17. Character by character translation.  against Urdu character. When replaced each character with Unicodes then it automatically converts into an Urdu lan- guage. Computer machines are all working on the function- ality of Unicode based linguistic. Then those converted Urdu characters create words and sentences. Figure 16 presents the results of each phase and sequence of the work ﬂow of the RUTUT translator. There are 15 Roman Urdu words gives to the RUTUT translator as input then it converts those words into a ﬁltered Romanized form. This Romanized form of words shown in the ﬁrst block of the second phase. There are 15 ﬁltered romanized words that are all in a capital case. These words were developed by the above preprocessing and rules-based character substitution modules. The second phase perform the Unicode based character mapping on this output of the First phase then successfully obtain Urdu translation of the 15 Roman Urdu words. All of the 15 words translated very perfectly by using the RUTUT translator.  C. RESULTS OF CHARACTER BY CHARACTER TRANSLATION The character by character translation presents in Figure 17. There is translation performed on a Roman Urdu sentence ‘‘ay khda rhm frma’’ and transform this sentence into its Urdu form.  First of all, preprocessing is applied to this sentence then split each word by using word tokenization such that ‘‘ ‘ay’,‘khda’,‘rhm’,‘frma’ ‘’. After this, rules based character substitution is applied on these words that further divide the words into letters and transform in Romanized Filtered form such that ‘‘ ’A’,‘E’,‘KH’,‘D’,‘A’,‘R’,‘H’,‘M’,‘F’,‘R’,‘M’,‘A’ ‘’. Then Unicode based character mapping applies to this form that transforms those letters into Urdu form and joins them to create Urdu words or sentences. Roman Urdu lan- guage is the one form of Urdu that is written by using English letters. That’s why Roman Urdu is right-hand side language that starts from the right-hand side and ends at the left-hand side.  When all letters are accurately mapped on the Urdu letters and Urdu form obtained then because of Unicode character mapping it automatically starts from the left-hand side. Urdu is the left-hand side language. After this a full sentence of proper formatted Urdu script is obtained. At the end, Urdu  FIGURE 18. Word based Roman Urdu script translation using RUTUT.  script is obtained in same sequence as the Roman Urdu Words. The character by character translation process is pre- sented in Figure 17 that shows how the translation process is done efﬁciently.  The performance of the proposed RUTUT translator needs to evaluate. For the evaluation process, two methods are used in the paper. First, adopt the fundamental approach in which 2000 Roman Urdu words are used as an input to the RUTUT translator. From which 1917 Roman Urdu word accurately translated into the Urdu language that shows the RUTUT translator 95.8% accurately translates the Roman Urdu words into the Urdu Language as shown in Table 3. The 144 Roman Urdu words as an example shown in Figure 18, are evaluated using RUTUT translator. From 144 Roman Urdu words, about ﬁve words are miss spelt in Urdu form and 139 words are accurately translated that shows 96% accu- rate transliteration results. Second, the comparison approach adopted to evaluate further that discussed in the next section.  189834  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 19. RUTUT’s Tkinter GUI that presents results of translations performed by RUTUT.  FIGURE 20. Comparison of the proposed RUTUT translator with ijunoon and Google online translator where ‘X’ presents the sentence contain mistakes in transliteration and ‘(cid:88)’ presents accurately translated sentences.  The RUTUT translator is shown in Figure 19 that con- sist of user friendly GUI. First, user needs to enter Roman  Urdu script as an input and then press the translate button. The Roman Urdu script goes through three major modules  VOLUME 8, 2020  189835  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 21. Transliteration results of the proposed approach RUTUT.  FIGURE 22. Transliteration results of the ijunoon online translator.  preprocessing, rule-based character substitution and Unicode based character mapping as shown in Figure 4 and 16.  Figure 19 presents the translation of the 12 sentences that are further compared with ijunoon and google online translators.  189836  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 23. Google online translator results after detection of Roman Urdu as a Romanian and Hindi language.  VOLUME 8, 2020  189837  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  TABLE 3. Transliteration Results based on Roman Urdu words.  TABLE 4. Comparison of the existing and purposed approach.  VI. COMPARISON OF THE EXISTING AND PROPOSED RUTUT TRANSLATOR In this research, the proposed approach RUTUT compares to the ijunoon [73] and google [74] online translator. Roman Urdu to Urdu script translators is already very few in this world. Many authors present their work on Roman Urdu to English translation but are very few for Urdu translation. Figure 20 consists of ﬁve columns which contain Roman Urdu input sentences, Google translator result 1, Google translator result 2, ijunoon translator results and RUTUT translator results. The twelve sentences are randomly selected to test the translator results and for their comparison with the proposed approach.  A. COMPARISON OF THE GOOGLE ONLINE TRANSLATOR RESULTS First, the Google translator [74] results are illustrated in this ﬁgure because Google is from one of the largest industry in the world that has a Google online translator for lan- guage translations. But the Google translator does not have any speciﬁc translator for the Roman Urdu because it is not the standard language. The Google translator relies on grammatical or translational rules of the other languages. When the user enters the Roman Urdu input then it auto- matically detects it as a Romanian or Hindi language and translates it into Urdu according to the rules of these lan- guages. That’s why there are two Google translator result1 and result2. Like in the ﬁrst sentence ‘surj chand khda kay bnae hue hain’ is translated into ‘Google Translator Result1’ that illustrates the google translator auto-detect the Roman Urdu script as a Romanian language and translate it into Roman Urdu according to the Romanian language rules. Sec- ond ‘Google Translator Result2’ auto-detect the Roman Urdu script as a Hindi language and translate it into Roman Urdu according to the Hindi language rules. Figure 20 presents that Google translator gives poor results in both outputs. It translates the Roman Urdu script into the Urdu sentence but not according to the transliterational concepts. It changes the meaning as well as phonetics of the language and does not perform translation for some sentences as shown in the column ‘Google translator result1’ sentence number 4, 5, 9, 10 and 11. Further, ‘X’ presents false or misspelt translations in Figure 20 and ‘(cid:88)‘ present correct translations without any single mistake. Only one sentence in the last of the second column ‘Google translator result2’ that depends on the rules of Hindi language, is correctly translated. Figure 23 displays the results of some sentences in which part a and b presents  the same sentence input but translated into different sentences according to Romanian and Hindi language rules. Same like this part c and d, e and f are also present different results.  B. COMPARISON OF THE IJUNOON ROMAN URDU TO URDU TRANSLITERATION RESULTS The ijunoon [73] online Roman Urdu to Urdu translator present the transliterational results according to exact pronun- ciations of the words. The 3rd column of the Figure 20 shows the results of the ijunoon translator with the same twelve sen- tences as used in the comparison. The ijunoon and proposed RUTUT translator gives better results than the Google online translator. The ijunoon translate all twelve sentences into the Urdu sentences but having mistakes in sentence number 1, 5, 9 and 12. But in comparison, the Proposed approach RUTUT translator only having a mistake in sentence number 1 and 3. The RUTUT translator gives better results than the ijunoon translator.  C. COMPARISON RESULTS OF PROPOSED APPROACH RUTUT: ROMAN URDU TO URDU TRANSLATOR The last column of Figure 20 presents the results of the proposed approach RUTUT translator. Figure 20 and discus- sion of previous comparison sections, clearly shows that the google translator is not able to translate the Roman Urdu script into the Urdu language because the google translator does not have any standard rules and grammar for the Roman Urdu script. The RUTUT translator translates all the sen- tences into accurate sentences according to the meaning and  189838  VOLUME 8, 2020  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  words. Twelve sentences translated by the RUTUT translator and 10 sentences are correctly translated without any mis- takes. Only two sentences, number 1 and 3 got minor mis- takes. The ijunoon is also shown mistakes in four sentences but RUTUT shows mistakes in only two sentences.  These results clearly show that the RUTUT translator gives much better results than Google and ijunoon online trans- lators because of its basic rules that are developed in this research to translate the Roman Urdu into Urdu script. These are the most latest online translator on the internet that does not have any speciﬁc rules and standards for Roman Urdu translator because Roman Urdu is not the standard language. Further, to evaluate the proposed research, Table 4 shows the comparison of the existing system with the proposed RUTUT translator that illustrates the novelty in terms of ﬁnd- ings and evaluates that the RUTUT translator outperforms the existing systems in comparison.  VII. CONCLUSION The RUTUT, a proposed translator translate the Roman Urdu script into Urdu script by using preprocessing, rule based character substitution and Unicode based character mapping techniques.  • At the initial stage, when the user gives a Roman Urdu script as an input then preprocessing rules are applied that ﬁlter unnecessary data. The rule-based character substitution process converts the ﬁltered form of Roman Urdu into a single standard form. The character mapping module based on Unicodes of Urdu characters against the Roman Urdu characters that convert the Roman Urdu form into Urdu Script.  • The evaluation of the proposed model presented by translating 2000 Roman Urdu words into Urdu in which 1917 words are accurately spelt that shows the 95.8% words are accurately translated. Furthermore, the RUTUT results are compared with the Google online translator and evaluated based on several sentences.  • This research successfully achieves its aims by develop- ing the translational rules for the Roman Urdu script and by developing a RUTUT translator based on these rules that translates Roman Urdu into Urdu script.  REFERENCES [1] P. Arora, D. Shterionov, Y. Moriya, A. Kaushik, D. Dzendzik, and G. Jones, ‘‘An investigative study of multi-modal cross-lingual retrieval,’’ in Proc. Workshop Cross-Lang. Search Summarization Text Speech (CLSSTS), 2020, pp. 58–67.  [2] J. Capstick, A. K. Diagne, G. Erbach, H. Uszkoreit, A. Leisenberg, and M. Leisenberg, ‘‘A system for supporting cross-lingual information retrieval,’’ Inf. Process. Manage., vol. 36, no. 2, pp. 275–289, Mar. 2000. [3] S. Mukund, R. Srihari, and E. Peterson, ‘‘An information-extraction sys- tem for Urdu—A resource-poor language,’’ ACM Trans. Asian Lang. Inf. Process., vol. 9, no. 4, pp. 1–43, Dec. 2010.  [4] K. Riaz, ‘‘Baseline for urdu IR evaluation,’’ in Proc. 2nd ACM Workshop Improving Non English Web Searching (iNEWS), New York, NY, USA, 2008, p. 97.  [5] M. Humayoun, H. Hammarström, and A. Ranta, ‘‘Urdu morphology, orthography and lexicon extraction,’’ in Proc. 2nd Workshop Comput. Approaches Arabic Script-Based Lang., 2007, pp. 6–40.  [6] K. Riaz, ‘‘Rule-based named entity recognition in Urdu,’’ in Proc. Named  Entities Workshop, 2010, pp. 126–135.  [7] F. Adeeba and S. Hussain, ‘‘Experiences in building urdu wordnet,’’ in  Proc. 9th Workshop Asian Lang. Resour., 2011, pp. 31–35.  [8] M. Shahroz, M. F. Mushtaq, M. Ahmad, S. Ullah, A. Mehmood, and G. S. Choi, ‘‘IoT-based smart shopping cart using radio frequency iden- tiﬁcation,’’ IEEE Access, vol. 8, pp. 68426–68438, 2020.  [9] M. J. H. Mughal, ‘‘Data mining: Web data mining techniques, tools and algorithms: An overview,’’ Int. J. Adv. Comput. Sci. Appl., vol. 9, no. 6, pp. 208–215, 2018.  [10] S. Bhatia, P. Chaudhary, and N. Dey, Opinion Mining in Information  Retrieval. Singapore: Springer, 2020.  [11] K. Mehmood, H. Afzal, A. Majeed, and H. Latif, ‘‘Contributions to the study of bi-lingual roman urdu SMS spam ﬁltering,’’ in Proc. Nat. Softw. Eng. Conf. (NSEC), Dec. 2015, pp. 42–47.  [12] N. Khan, M. P. Bakht, M. J. Khan, A. Samad, and G. Sahar, ‘‘Spotting urdu stop words by Zipf’s statistical approach,’’ in Proc. 13th Int. Conf. Math., Actuarial Sci., Comput. Sci. Statist. (MACS), Dec. 2019, pp. 1–5.  [13] W. Khan, A. Daud, K. Khan, J. A. Nasir, M. Basheri, N. Aljohani, and F. S. Alotaibi, ‘‘Part of speech tagging in urdu: Comparison of machine and deep learning approaches,’’ IEEE Access, vol. 7, pp. 38918–38936, 2019.  [14] T. Ehsan and S. Hussain, ‘‘Analysis of experiments on statistical and neural parsing for a morphologically rich and free word order language urdu,’’ IEEE Access, vol. 7, pp. 161776–161793, 2019.  [15] E. T. Al-Shammari and J. Lin, ‘‘Towards an error-free Arabic stemming,’’ in Proc. 2nd ACM Workshop Improving Non English Web Searching, 2008, pp. 9–16.  [16] B. Jawaid and T. Ahmed, ‘‘Hindi to Urdu conversion: Beyond simple  transliteration,’’ in Proc. Conf. Lang. Technol., 2009, pp. 1–8.  [17] K. Mehmood, D. Essam, K. Shaﬁ, and M. K. Malik, ‘‘Sentiment analysis for a resource poor language-Roman Urdu,’’ ACM Trans. Asian Low- Resource Lang. Inf. Process., vol. 19, no. 1, pp. 1–15, 2019.  [18] W. Anwar, X. Wang, and X.-L. Wang, ‘‘A survey of automatic urdu lan- guage processing,’’ in Proc. Int. Conf. Mach. Learn. Cybern., Aug. 2006, pp. 4489–4494.  [19] G. A. Miller, ‘‘WordNet: A lexical database for English,’’ Commun. ACM,  vol. 38, no. 11, pp. 39–41, 1995.  [20] Q.-U.-A. Akram, A. Naseer, and S. Hussain, ‘‘Assas-band, an afﬁx- exception-list based urdu stemmer,’’ in Proc. 7th Workshop Asian Lang. Resour. (ALR), 2009, pp. 40–46.  [21] A. Bilal, A. Rextin, A. Kakakhel, and M. Nasim, ‘‘Roman-Txt: Forms and functions of Roman Urdu texting,’’ in Proc. 19th Int. Conf. Hum.-Comput. Interact. Mobile Devices Services (MobileHCI), 2017.  [22] Y. Li and T. Yang,  ‘‘Word embedding for understanding natural language: A survey,’’ in Guide to Big Data Applications, vol. 26. Cham, Switzerland: Springer, 2018, pp. 83–104. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-319-53817-4_4  [23] T. Ahmed, ‘‘Roman to Urdu transliteration using wordlist,’’ in Proc. Conf.  Lang. Technol., vol. 305, 2009, p. 309.  [24] H. Taghi-Zadeh, M. H. Sadreddini, M. H. Diyanati, and A. H. Rasekh, ‘‘A new hybrid stemming method for Persian language,’’ Digit. Scholarship Humanities, vol. 32, no. 1, pp. 209–221, 2017.  [25] A. Daud, W. Khan, and D. Che, ‘‘Urdu language processing: A survey,’’  Artif. Intell. Rev., vol. 47, no. 3, pp. 279–311, Mar. 2017.  [26] H. Masroor, M. Saeed, M. Feroz, K. Ahsan, and K. Islam, ‘‘Transtech: Development of a novel translator for roman urdu to english,’’ Heliyon, vol. 5, no. 5, May 2019, Art. no. e01780.  [27] F. Memood, M. Usman Ghani, M. Ali Ibrahim, R. Shehzadi, and M. Nabeel Asim, ‘‘A precisely xtreme-multi channel hybrid approach for roman urdu sentiment analysis,’’ 2020, arXiv:2003.05443. [Online]. Available: http://arxiv.org/abs/2003.05443  [28] A. Z. Syed, M. Aslam, and A. M. Martinez-Enriquez, ‘‘Associating targets with SentiUnits: A step forward in sentiment analysis of urdu text,’’ Artif. Intell. Rev., vol. 41, no. 4, pp. 535–561, Apr. 2014.  [29] D. E. Kieras and M. A. Just, New Methods in Reading Comprehension  Research. Evanston, IL, USA: Routledge, 2018.  [30] T. Ahmed and A. Hautli, ‘‘Developing a basic lexical resource for Urdu using Hindi WordNet,’’ in Proc. CLT, Islamabad, Pakistan, 2010, pp. 1–8. [31] V. Gupta, N. Joshi, and I. Mathur, ‘‘Design & development of rule based inﬂectional and derivational Urdu stemmer ‘Usal,’’’ in Proc. Int. Conf. Futuristic Trends Comput. Anal. Knowl. Manage. (ABLAZE), Feb. 2015, pp. 7–12.  VOLUME 8, 2020  189839  \\x0cM. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  [32] M. Alam and S. ul Hussain, ‘‘Sequence to sequence networks for roman-urdu to urdu transliteration,’’ in Proc. Int. Multi-topic Conf. (INMIC), Nov. 2017, pp. 1–7.  [33] V. Gupta, N. Joshi, and I. Mathur, ‘‘Rule based stemmer in urdu,’’ in Proc. 4th Int. Conf. Comput. Commun. Technol. (ICCCT), Sep. 2013, pp. 129–132.  [34] M. S. Husain, F. Ahamad, and S. Khalid, ‘‘A language Independent in Advances in Computing Approach to develop Urdu stemmer,’’ and Information Technology (Advances in Intelligent Systems and Computing), vol. 178, N. Meghanathan, D. Nagamalai, and N. Chaki, Eds. Berlin, Germany: Springer, 2013, pp. 45–53. [Online]. Available: https://link.springer.com/chapter/10.1007/978-3-642-31600-5_5, doi: 10.1007/978-3-642-31600-5_5.  [35] K. Cho, B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, representations statistical machine translation,’’ https://arxiv.org/abs/  H. Schwenk, using RNN encoder-decoder 2014, 1406.1078  [Online]. Available:  ‘‘Learning phrase  and Y. Bengio,  arXiv:1406.1078.  for  [36] O. Vinyals and Q. Le,  ‘‘A neural conversational model,’’ 2015, https://arxiv.org/abs/1506.  [Online]. Available:  arXiv:1506.05869. 05869  [37] M. Z. Asghar, A. Sattar, A. Khan, A. Ali, F. Masud Kundi, and S. Ahmad, ‘‘Creating sentiment lexicon for sentiment analysis in Urdu: The case of a resource-poor language,’’ Expert Syst., vol. 36, no. 3, 2019, Art. no. e12397.  [38] T. Naseem and S. Hussain, ‘‘A novel approach for ranking spelling error corrections for urdu,’’ Lang. Resour. Eval., vol. 41, no. 2, pp. 117–128, Nov. 2007.  [39] S. Iqbal, W. Anwar, U. I. Bajwa, and Z. Rehman, ‘‘Urdu spell checking: Reverse edit distance approach,’’ in Proc. 4th Workshop South Southeast Asian Natural Lang. Process., 2013, pp. 58–65.  [40] M. Daud, R. Khan, Mohibullah, and A. Daud, ‘‘Roman urdu opinion mining system (RUOMiS),’’ 2015, arXiv:1501.01386. [Online]. Available: http://arxiv.org/abs/1501.01386  [41] S. Mukund and R. K. Srihari, ‘‘NE tagging for urdu based on bootstrap POS learning,’’ in Proc. 3rd Int. Workshop Cross Lingual Inf. Access Addressing Inf. Need Multilingual Societies (CLIAWS), 2009, pp. 61–69.  [42] M. Bilal, H. Israr, M. Shahid, and A. Khan, ‘‘Sentiment classiﬁcation of Roman-Urdu opinions using Naïve Bayesian, Decision Tree and KNN classiﬁcation techniques,’’ J. King Saud Univ.-Comput. Inf. Sci., vol. 28, no. 3, pp. 330–344, 2016.  [43] M. Vathsala and G. Holi, ‘‘RNN based machine translation and translit- eration for Twitter data,’’ Int. J. Speech Technol., vol. 23, pp. 499–504, Jun. 2020.  [44] S. M. Ash, ‘‘Transliteration of data records for improved data matching,’’  U.S. Patent App. 16 197 222, May 21, 2020.  [45] M. Rauf and S. Padó, ‘‘Learning trilingual dictionaries for Urdu–Roman  Urdu–English,’’ in Proc. Workshop Widening NLP, 2019, pp. 38–42.  [46] Z. Sharf and S. U. Rahman, ‘‘Lexical normalization of roman Urdu text,’’  Int. J. Comput. Sci. Netw. Secur., vol. 17, no. 12, pp. 213–221, 2017.  [47] M. Faruqui, P. Majumder, and S. Padó, ‘‘Soundex-based translation correc- tion in Urdu–English cross-language information retrieval,’’ in Proc. 5th Int. Workshop Cross Lingual Inf. Access, 2011, pp. 25–29.  [48] R. Aziz and M. W. Anwar, ‘‘Urdu spell checker: A scarce resource language,’’ in Proc. Int. Conf. Intell. Technol. Appl. Springer, 2019, pp. 471–483.  [49] M. A. Zahid, N. I. Rao, and A. M. Siddiqui, ‘‘English to urdu translitera- tion: An application of soundex algorithm,’’ in Proc. Int. Conf. Inf. Emerg. Technol., Jun. 2010, pp. 1–5.  [50] N. Mathur, T. Baldwin, and T. Cohn, ‘‘Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics,’’ 2020, arXiv:2006.06264. [Online]. Available: http://arxiv.org/abs/2006.06264  [51] M. P. Akhter, Z. Jiangbin, I. R. Naqvi, M. Abdelmajeed, and M. T. Sadiq, ‘‘Automatic detection of offensive language for urdu and roman urdu,’’ IEEE Access, vol. 8, pp. 91213–91226, 2020.  [52] Y. Wu et al., ‘‘Google’s neural machine translation system: Bridg- ing the gap between human and machine translation,’’ 2016, pp. 1–23, arXiv:1609.08144. [Online]. Available: https://arxiv.org/abs/1609.08144 [53] I. Sutskever, O. Vinyals, and Q. V. Le, ‘‘Sequence to sequence learning with neural networks,’’ in Proc. Adv. Neural Inf. Process. Syst., 2014, pp. 3104–3112.  [54] W. Ling, I. Trancoso, C. Dyer, and A. W. Black, ‘‘Character-based neu- ral machine translation,’’ 2015, arXiv:1511.04586. [Online]. Available: https://arxiv.org/abs/1511.04586  [55] C. D. Manning,  ‘‘Effective approaches  machine translation,’’ 2015, arXiv:1508.04025. https://arxiv.org/abs/1508.04025  to attention-based neural [Online]. Available:  [56] P. Agrawal and L. Jain, ‘‘English to Sanskrit transliteration: An effec- Int. J. tive approach to design natural Adv. Res. Comput. Sci., vol. 8, no. 1, pp. 103–107, 2017. [Online]. Available: http://www.ijarcs.info/index.php/Ijarcs/article/view/2860, doi: 10.26483/ijarcs.v8i1.2860.  language translation tool,’’  [57] N. Jadoon Khan, W. Anwar, and N. Durrani, ‘‘Machine translation approaches and survey for indian languages,’’ 2017, arXiv:1701.04290. [Online]. Available: http://arxiv.org/abs/1701.04290  [58] A. Khattak, M. Z. Asghar, A. Saeed, I. A. Hameed, S. A. Hassan, and S. Ahmad, ‘‘A survey on sentiment analysis in Urdu: A resource- poor language,’’ Egyptian Inform. J., Mar. 2020. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S1110866520301171, doi: 10.1016/j.eij.2020.04.003.  [59] P. Juola, ‘‘Self-organizing machine translation: Example-driven induction of transfer functions,’’ 1994, arXiv:cmp-lg/9406012. [Online]. Available: https://arxiv.org/abs/cmp-lg/9406012  [60] P. Koehn, ‘‘Europarl: A parallel corpus for statistical machine translation,’’  in Proc. MT Summit, vol. 5. Citeseer, 2005, pp. 79–86.  [61] Center of Language Engineering. Accessed: May 5, 2020. [Online]. Avail-  able: http://www.cle.org.pk/software/localization.htm  [62] A. Hardie, ‘‘Developing a tagset for automated part-of-speech tagging in Urdu,’’ in Proc. Corpus Linguistics. Lancashire, U.K.: Lancaster Univ., 2003, p. 103. [Online]. Available: https://eprints.lancs.ac.uk/id/eprint/103 [63] D. Becker and K. Riaz, ‘‘A study in Urdu corpus construction,’’ in Proc. 3rd Workshop Asian Lang. Resour. Int. Standardization (COLING), 2002. [Online]. Available: https://www.aclweb.org/anthology/W02-1201  [64] M. Gorelick and I. Ozsvald, High Performance Python: Practical Perfor- mant Programming for Humans. Sebastopol, VA, USA: O’Reilly Media, 2020.  [65] N. Silaparasetty, ‘‘Python programming in Jupyter notebook,’’ in Machine Learning Concepts with Python and the Jupyter Notebook Environment. Berkeley, CA, USA: Springer, 2020, pp. 119–145, doi: 10.1007/978-1- 4842-5967-2_7.  [66] G. Moruzzi, ‘‘Python basics and the interactive mode,’’ in Essential Python for the Physicist. Cham, Switzerland: Springer, 2020, pp. 1–39, doi: 10.1007/978-3-030-45027-4_1.  [67] M. J. Denny and A. Spirling, ‘‘Text preprocessing for unsupervised learn- ing: Why it matters, when it misleads, and what to do about it,’’ Political Anal., vol. 26, no. 2, pp. 168–189, Apr. 2018.  [68] S. Kannan, V. Gurusamy, S. Vijayarani, J. Ilamathi, M. Nithya, S. Kan- nan, and V. Gurusamy, ‘‘Preprocessing techniques for text mining,’’ Int. J. Comput. Sci. Commun. Netw., vol. 5, no. 1, pp. 7–16, 2015.  [69] S. Vijayarani and R. Janani, ‘‘Text mining: Open source tokenization tools-an analysis,’’ Adv. Comput. Intell., Int. J., vol. 3, no. 1, pp. 37–47, 2016.  [70] T. Hiraoka, H. Shindo, and Y. Matsumoto, ‘‘Stochastic tokenization with a language model for neural text classiﬁcation,’’ in Proc. 57th Annu. Meeting Assoc. Comput. Linguistics, 2019, pp. 1–10.  [71] M. Davis and L. Collins, ‘‘Unicode,’’ in Proc. IEEE Int. Conf. Syst., Man,  Cybern. Conf., Nov. 1990, pp. 499–504.  [72] M. Needleman, ‘‘The unicode standard,’’ Serials Rev., vol. 26, no. 2,  pp. 51–54, 2000.  [73] ijunoon: Roman Urdu To Urdu Script Transliteration. Accessed: https://www.ijunoon.com/  [Online]. Available:  2020.  27,  Oct. transliteration/roman-to-urdu  [74] Google Online Translator. Accessed: Oct. 27, 2020. [Online]. Available:  https://translate.google.com/?hl=en&tab=tt  [75] M. Y. Khan and T. Ahmed, ‘‘Pseudo transfer learning by exploiting mono- lingual corpus: An experiment on roman Urdu transliteration,’’ in Proc. Int. Conf. Intell. Technol. Appl. (INTAP), in Communications in Computer and Information Science, I. Bajwa, T. Sibalija, and D. Jawawi, Eds. Singapore: Springer, 2019, pp. 422–431, doi: 10.1007/978-981-15-5232-8_36.  [76] S. Qazi and H. Tariq, ‘‘A novel and efﬁcient method for roman to urdu transliteration via heuristics-based searching on parse trees,’’ Int. Trans. J. Eng., Manage., Appl. Sci. Technol., vol. 10, no. 3, pp. 567–577, 2019.  189840  VOLUME 8, 2020  \\x0cSALEEM ULLAH was born in AhmedPur East, Pakistan, in 1983. He received the B.Sc. and MIT degrees in computer science from Islamia Uni- versity Bahawalpur and Bahauddin Zakariya Uni- versity, Multan, in 2003 and 2005, respectively, and the Ph.D. degree from Chongqing University, China, in 2012. From 2006 to 2009, he worked as a Network/IT Administrator in different companies. From August 2012 to February 2016, he worked as an Assistant Professor with Islamia University Bahawalpur, Pakistan. He is currently working as an Associate Professor with the Khwaja Fareed University of Engineering and Information Tech- nology, Rahim Yar Khan, since February 2016. He has almost 13 years of Industry experience in the ﬁeld of IT. He is an active researcher in the ﬁeld of adhoc networks, congestion control, and security.  M. Shahroz et al.: RUTUT Based on Character Substitution Rules and Unicode Mapping  supervised and unsupervised machine learning, and image processing.  MOBEEN SHAHROZ received the M.C.S. degree from the Department of Computer Science, Khawaja Fareed University of Engineering and Information Technology (KFUEIT), Rahim Yar Khan, Pakistan, in 2018, where he is currently pur- suing the M.S. degree in computer science. He is currently serving as a Research Assistant with KFUEIT. His current research interest includes the Internet of Things (IoT), artiﬁcial intelligence, data mining, natural language processing (NLP),  MUHAMMAD FAHEEM MUSHTAQ received the B.S. (IT) and M.S. (CS) degrees from The Islamia University of Bahawalpur, Punjab, Pak- istan, in 2011 and 2013, respectively, the Microsoft certiﬁcations of Internet Security and Accelera- tion (ISA) Server, Microsoft Certiﬁed Professional (MCP), Microsoft Certiﬁed Technology Profes- sional (MCTS), in 2010, and the Ph.D. degree from the Department of Information Security, Faculty of Computer Science and Information Technology,  University Tun Hussein Onn Malaysia (UTHM), Malaysia, in 2018.  He has made several contributions through research publications and book chapters toward information security. He is currently working as an Assistant Professor with the Department of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim yar Khan, Pakistan. He has been working as a Research Assistant during his Ph.D. degree from March 2016 to August 2018. He has been appointed as the Vice President of UTHM’s Graduates Student Association from 2017 to 2018. His main research interests include information security, data mining, as well as cognitive system and applications.  ARIF MEHMOOD received the Ph.D. degree from the Department of Information and Com- munication Engineering, Yeungnam University, South Korea, from February 2014 to November 2017. Since November 2017, he has been an Assistant Professor with the Department Infor- mation Technology, The Islamia University of Bahawalpur, Pakistan. His current research inter- ests include data mining, mainly working on AI and deep learning-based on text mining, and data  GYU SANG CHOI (Member, IEEE) received the Ph.D. degree in computer science and engi- neering from Pennsylvania State University. He was a Research Staff Member with the Sam- sung Advanced Institute of Technology (SAIT), Samsung Electronics Company Ltd., from 2006 to 2009. Since 2009, he has been with Yeung- nam University, where he is currently a Professor. His research interests include data mining, deep learning and parallel computing, while his prior research has been mainly focused on improving the performance of clusters. He is a member of ACM.  science management technologies.  VOLUME 8, 2020  189841  \\x0c'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "VmXIqqJ4Z31Q",
        "outputId": "267ff93d-1a24-4afe-ef0d-9fca4dc71bec"
      },
      "source": [
        "summarized[13]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Received September 30, 2020, accepted October 12, 2020, date of publication October 15, 2020, date of current version October 28, 2020. The foun- dation of Urdu is lies in Arabic, Persian and most of the South Asian languages. The structure of the paper categorised into the following sections: section II presents the Roman Urdu in which the impact and inﬂuences of the Roman Urdu language is dis- cussed. Local users need to use Roman Urdu in daily life. Mostly ‘ain’ and ‘alif’ occurs at the start of the word like ‘adal’ and ‘alag’ both have vowel letter ‘a’ in Roman Urdu that is equivalent to diacritic mark ‘zabar’ in Urdu as shown in Figure 5. The general- ized form of the rule comes forward after all the special rules. RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 14. Character mapping is the phase in which a preprocessed and rule-based substitutions are applied to Roman Urdu and a form of Roman Urdu is  189832  VOLUME 8, 2020  \\x0cM. Shahroz et al.: A. COMPARISON OF THE GOOGLE ONLINE TRANSLATOR RESULTS First, the Google translator [74] results are illustrated in this ﬁgure because Google is from one of the largest industry in the world that has a Google online translator for lan- guage translations. The character mapping module based on Unicodes of Urdu characters against the Roman Urdu characters that convert the Roman Urdu form into Urdu Script. VOLUME 8, 2020  189839  \\x0cM. Shahroz et al.: 05869  [37] M. Z. Asghar, A. Sattar, A. Khan, A. Ali, F. Masud Kundi, and S. Ahmad, ‘‘Creating sentiment lexicon for sentiment analysis in Urdu: The case of a resource-poor language,’’ Expert Syst., Cham, Switzerland: Springer, 2020, pp.'"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wVqf57iaFwg",
        "outputId": "c33ad603-4e5c-45d1-fc2b-843e0c20955d"
      },
      "source": [
        "summarized"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['37  Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 37–42,  Jeju, Republic of Korea, 8-14 July 2012. 2.1  Architecture  As already mentioned, IRIS architecture is heavily  based on a vector space model framework, which  includes a standard similarity search module from  vector-based information retrieval systems (Salton  and  McGill,  1983). Just after the dynamic replacement is conducted,  tokenization and vectorization of the user input is  carried  out. If IRIS decides not to ask for the meaning of the  OOV term, or if no OOV term has been identified,  vectorization of the user input is completed by the  vector similarity modules and similarity scores are  computed  for  retrieving  best  matches  from  the  dialogue database. Table 2: Beginning of a chat session between IRIS   and a new user     For the dialogue depicted in Table 2, turn num- bers 1, 2 and 3 are processed by the dialogue intia- tion/ending  module. 6  7  USER  Paella  8  9  USER  It is a Spanish food. 12    Table 4: Chat segment in which IRIS learns the   IRIS  Well, it beats working in a seafood restaurant...  new vocabulary term paella         Notice  that  when  the  user  asks  IRIS  about  having some paella today, IRIS is already able to  associate  it  with  seafood  as  it  was  stated  in  the  user’s  provided  definition. The actual user input that is  finally vectorized in turn 11 is the following one:  so  do  you  want  some  it  is  a  spanish  food  yellow   rice with some seafood on it today ?, IRIS  You watching the ballgame? More specifically, IRIS is capable of learning new  vocabulary terms and semantically relating them to  previous  knowledge,  as  well  as  adapting  its  dia- logue decisions to some stated user preferences. of the 5th  Conference on Applied NLP, pp 25-32. Salton  G,  Buckley  C  (1988)  Term-weighting  approa- ches in automatic text retrieval. Spark K (1972) A statistical interpretation of term speci- ficity and its application in retrieval.',\n",
              " 'An Attention Based Neural Network for Code Switching Detection:  English & Roman Urdu  Aizaz Hussain, Muhammad Umair Arshad Artiﬁcial Intelligence & Machine Learning lab  National University of Computer and Emerging Sciences, FAST  {aizaz.hussain,umair.arshad}@nu.edu.pk  Islamabad, Pakistan  Abstract  Code-switching is a common phenomenon among people with diverse lingual background and is widely used on the internet for commu- nication purposes. Code-Mixing means that in a single sentence a per- son uses multilingual vocabulary, grammar for the delivery of meaningful information. Our paper makes the following contributions: 1) We show that extrac- tion with the use of attention model improves the accuracy 2) Code mixing language identiﬁcaiton for low resource language i.e. English and Roman Urdu 3) We present a new public dataset to support research on code mixed language identiﬁcation on Roman Urdu and English  In this paper, we propose to use the transformer- based neural network for the detection of Multi- lingual text in English and Urdu from the given dataset. This allows us to make a ﬂow of informa- tion between different steps. We are not discarding the variations of spellings for a word because our goal is to pay attention to the words pronunciation representation of words in the vector space. Table 2: The table shows the numbers of data tokens splitted in order to train and test the models. HMM is a statisti- cal model which works on the probability of state  2https://www.ijunoon.com/  transliteration/urdu-to-roman  Figure 4: The architecture of Hidden Markov Model in which the connection with label a shows the hidden states of the model while b shows the output states. Mubashar Nazar Awan and Mirza Omer Beg. Abdul Rehman Javed, Muhammad Usman Sarwar, Mirza Omer Beg, Muhammad Asim, Thar Baker, and Hissam Tawﬁk. Processing of sentences with In Coling 1982: intra-sentential code-switching. Future Generation Computer Systems, 92:745–757. Adeel Zafar, Hasan Mujtaba, Mirza Omer Beg, and  Sajid Ali. Relationship identiﬁcation be- tween conversational agents using emotion analysis.',\n",
              " 'Learning Trilingual Dictionaries for Urdu – Roman Urdu – English  Moiz Rauf and Sebastian Padó  Institut für Maschinelle Sprachverarbeitung  University of Stuttgart, Germany  {moiz.rauf,pado}@ims.uni-stuttgart.de  Abstract  In this paper, we present an effort to generate a joint Urdu, Roman Urdu and English trilingual lexicon using automated methods. To capture the colloquial nature of Roman Urdu and its relation to Urdu, we used the annotated SMS text parallel corpus developed by Irvine et al. ( While, in 16% of translations Urdu terms were loaned/borrowed English words (e.g. motor → ramp, lady → liberty, watt → kw etc). Our results and error analysis have revealed that our method encapsulates signiﬁcant information to capture bilingual semantic relationships and that it is a concrete bootstrapping lexicon which can be built upon and has utility in various linguistic tasks. Using parallel corpora to create a Greek-English dictionary with Uplug. Identifying word correspondence in parallel texts. Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, and Tomas Mikolov. A systematic comparison of various statistical alignment  models. Learning bilingual lexicons from comparable English and Spanish corpora. Yves Peirsman and Sebastian Padó. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 401–409, Montréal, Canada. Creating a free digital Japanese-Swedish lexicon. In 22nd Paciﬁc Asia Conference on Information Systems, PACIS 2018, page 96.',\n",
              " 'The user has requested enhancement of the downloaded file. At  this stage, the parallel corpus comprises 127K pairs of Roman Urdu and standard  Urdu tokens. Hence,  this  concept  can  be  termed  as  “Pseudo Transfer Learning” (PTL) such that other experiments in ANN can take benefit  from  the  pseudo-knowledge  if  the  weights  (calibrated  through  echoing  monolingual  corpus) transferred to them at the step of weight-initialization. In NLP, Sequence to Sequence (Seq2Seq) processing involves tasks that work on a  sequence of information (𝒮𝑖) and produce another sequence (𝒮𝑡) in result, where 𝒮𝑖 and  𝒮𝑡 are the source and target sequence respectively, and 𝒮𝑖 ≠ 𝒮𝑡. Machine translation,  transliteration,  and  transcription  of  a  language  into  any  other  language/script  can  be  accounted as few examples of Seq2Seq processing [33, 2, 3]. 2.1  Review of Roman Urdu Transliteration   Work has been done for both Roman to Urdu (e.g. [35]) and vice versa (e.g. [23, 7]). In contrast with the method discussed for Roman Urdu transliteration in the paper  [2]; our approach uses the character-based LSTM model, whereas, word- level LSTM  model is employed in the work as mentioned earlier. In the initial (pre-training) phase monolingual corpus is  copied and the network is trained for 100 epochs to tune weights, then in the later phase,  these weights are transferred to train the network on the original parallel corpus of Ro- man Urdu and respective Urdu sequences to achieve transfer learning. However,  the  306.9K  distinct  tokens  were yielded from the ℳ. These tokens are employed for the development of ℳ𝑝.    The  parallel  corpus  of  Romanized-Urdu  and  standard  Urdu  pairs  is  constructed  through  scrapping  iJunoon.com2,  where  the  English-Urdu  dictionary  facilitates  users  with the meaning of an English word in standard Urdu script (α) along with its translit- erated version in Roman script (λ). Fig 2: Comparative plot of loss values along epochs. Baxter, J., Caruana, R., Mitchell, T., Pratt, L.Y., Silver, D.L., Thrun, S.: Learning to learn:  Knowledge  consolidation  and  trans-  fer  in  inductive  systems. arXiv preprint arXiv:1409.1259 (2014)    11. In: Proceedings of the 23rd Interna- tional Conference on Computational Lin- guistics. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural networks.',\n",
              " 'Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 823–828,  Lisbon, Portugal, 17-21 September 2015. These inconsistencies cause a problem of data sparsity in basic natural language processing  tasks such as Urdu word segmentation (Durrani and Hussain, 2010), part of speech tagging (Saj- jad and Schmid, 2009), spell checking (Naseem and Hussain, 2007), machine translation (Durrani et al., 2010) used string edit distance to ﬁnd candidate lexical variations. 4.1 Dataset and Gold Standard The ﬁrst dataset, Web dataset, is scraped from Ro- man Urdu websites on news5, poetry6, SMS7 and blog8. Overlap with gold standard = number of words ap- pearing in gold standard; UrduPhone IDs = num- ber of distinct UrduPhone encodings. IDs while the left y-axis gives the precision, recall, and f- measure and the right y-axis shows the difference between the number of predicted and actual clus- ters. In these results, the simi- larity threshold t is selected such that the number of discovered clusters is as close as possible to the number of actual clusters in the gold standard for each dataset. The best performances are obtained when UrduPhone is used as a feature and UrduPhone IDs are used to deﬁne the context (Exp. Normal- ization of noisy text data. Association for Computational Linguistics. Malik Tahir Hassan, Khurum Nazir Junejo, and Asim Karim. A rule-based model for normalization of sms text. Richard Sproat, Alan W. Black, Stanley F. Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards.',\n",
              " 'LREC 2016  11th Workshop on  Building and Using Comparable Corpora  PROCEEDINGS  Edited by  Reinhard Rapp, Pierre Zweigenbaum, Serge Sharoff  ISBN: 979-10-95546-07-8  EAN: 9791095546078  8 May 2018  Proceedings of the 11th Workshop on Building and Using Comparable Corpora, 8 May 2018 – LREC 2018, Miyazaki, Japan  \\x0cEdited by Reinhard Rapp, Pierre Zweigenbaum, Serge Sharoff  https://comparable.limsi.fr/bucc2018/  Acknowledgments: Part of this work was supported by a Marie Curie Career Integration Grant (MUL- TILEX) within the 7th European Community Framework Programme. Reinhard Rapp, Pierre Zweigenbaum, Serge Sharoff (eds.) When term variations exist, i.e. different representational forms are regarded as represent- ing the same concept (Daille, 2017), controlling the surface form of terms also becomes an issue accompanying devia- tion detection. Such an approach results in a new starting point for the type of lexical experiments we will perform later. Identifying Bilingual Topics in Wikipedia for Efﬁcient Parallel Corpus  Extraction and Building Domain-Speciﬁc Glossaries for the Japanese-English  Language Pair  Bartholom¨aus Wloka  University of Vienna  Centre for Translation Studies  bartholomaeus.wloka@univie.at.at  Abstract  This paper presents an approach and its implementation as a software toolset for examining what portion of the multilingual content of Wikipedia is viable for harvesting bilingual data in order to build parallel corpora and domain-speciﬁc glossaries. Association for Computa- tional Linguistics. In this exam- ple, the variation in both languages can be represented as:  logical clusters from textual data. This toolkit is used for computing continuous rep- resentations for text at different granularity levels (word- level or sequences of words).1 Similarly to word2vec (Mikolov et al., • General features: For each sentence, we use differ- ent features modeling its length in terms of words, the ratio of source-target length, source-target punctuation marks, numerical characters, and source-target content words.3  1https://github.com/eske/multivec 2Since we are working with vector representations, doing the  Cartesian product is possible. In Proceedings of the 54th Annual Meeting of the Asso- ciation for Computational Linguistics (Volume 1: Long Papers), pages 1715–1725, Berlin, Germany. Specia, L., Paetzold, G., and Scarton, C. (2015). Zou, W. Y., Socher, R., Cer, D., and Manning, C. D. (2013). Experimental Settings The volumes of data selected for the task makes it unrealis- tic to compute the alignments over the Cartesian products of source and target sentences.',\n",
              " '6 1 0 2     y a M 9 1         ] L C . Recently, a number of papers have proposed the use of neural networks to directly learn this condi- tional distribution (see, e.g., Kalchbrenner and Blunsom, 2013; Cho et al., 2014) reported that the neural machine translation based on RNNs with long short- term memory (LSTM) units achieves close to the state-of-the-art performance of the conventional phrase-based machine translation system on an English-to-French translation task.1 Adding neural components to existing translation systems, for instance, to score the phrase pairs in the phrase table (Cho et al., 2  \\x0cPublished as a conference paper at ICLR 2015  T(cid:89)  The decoder is often trained to predict the next word yt(cid:48) given the context vector c and all the previously predicted words {y1,··· , yt(cid:48)−1}. (5)  Tx(cid:88)  j=1  The weight αij of each annotation hj is computed by  Figure 1: The graphical illus- tration of the proposed model trying to generate the t-th tar- get word yt given a source sentence (x1, x2, . . . , 5.2 QUALITATIVE ANALYSIS  5.2.1 ALIGNMENT  The proposed approach provides an intuitive way to inspect the (soft-)alignment between the words in a generated translation and those in a source sentence. 2 the proposed model (RNNsearch) is much better than the conventional model (RNNencdec) at translating long sentences. From the qualitative analysis where we investigated the (soft-)alignment generated by the RNNsearch, we were able to conclude that the model can cor- rectly align each target word with the relevant words, or their annotations, in the source sentence as it generated a correct translation. Association for Computational Linguistics. In Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. Pascanu, R., Gulcehre, C., Cho, K., and Bengio, Y. (2014). (7)  (cid:35)  (cid:34) −→  h i←− h i  hi =  The hidden state si of the decoder given the annotations from the encoder is computed by  A.2.2 DECODER  where  si =(1 − zi) ◦ si−1 + zi ◦ ˜si,  ˜si = tanh (W Eyi−1 + U [ri ◦ si−1] + Cci) zi =σ (WzEyi−1 + Uzsi−1 + Czci) ri =σ (WrEyi−1 + Ursi−1 + Crci)  E is the word embedding matrix for the target language. Lors d’une conf´erence de presse jeudi, M. Blair a d´eclar´e qu’il n’y avait rien dans cette vid´eo qui pourrait constituer un ”motif raisonnable” qui pourrait conduire `a des accusations criminelles contre le maire.',\n",
              " 'Machine Translation Approaches and Survey for Indian Languages    Nadeem Jadoon Khan*    Waqas Anwar*       Nadir Durrani**      *COMSAT University   **University of Edinburgh         ABSTRACT:  In  this study,  we  present  an  analysis  regarding  the performance of  the  state-of-art  Phrase- based  Statistical  Machine Translation (SMT)  on  multiple  Indian  languages. Given  a  source  sentence  F,  the  objective  is  to  find  a  target  sentence  E,  which  maximizes the likelihood of two components, the translation (or adequacy) and the language (or fluency  model). The next step is to train the language model on the corpus that is suitable to the domain. The  monolingual  corpora  collected  for  this  study  have  around  60  million tokens  distributed  in  nearly  2  million sentences. Results   As the languages used in this work are sparse-resourced, we achieved relatively lower scores for BLEU  (Papineni, 2002), we have achieved BLEU score with a mean of 0.12 and a Standard deviation of 0.06 on  the given test sets using the 5-fold cross validation method. Translation  output of our developed system is given below in example. From the phrase table it is seen that  many source words are translated to just single target output. In Proceedings  of the 14th Annual conference of the European Association for Machine Translation. In Human Language Technologies: The 2010 Annual  Conference of the North American Chapter of the Association for Computational Linguistics, pages 528–536. Sharma,  N.,  Parteek  Bhatia,  Varinderpal  Singh. The Editors of Encyclopædia Britannica. \" Encyclopedia Britannica Online.',\n",
              " 'Even though an important eﬀort has been that best preserves the phonetic and orthographic aspects of the transliterated words. In this work, an attention-based encoder-decoder system is proposed for the task of Machine Transliteration between the Arabic and English languages. In such situations, this kinds of characters will need to be either omitted or even approximated depending on their context of occurrence. Section 2 presents relevant related work in this area and motivates our contribution. 290  4  Mohamed Seghir Hadj Ameur et al. / The second aspect aims at comparing the performance of our proposal with the Phrase-based Statistical Machine Translation system which has been proven to perform very well at sequence-to-sequence prediction tasks. (11)  (12)  ˆe = argmaxe = (  1 αmϕm( f,e)  )  1 αmϕm( f,e(cid:29))  exp(cid:31)M (cid:31)e(cid:29) exp(cid:31)M  6 https://nlp.stanford.edu/software/CRF-NER.shtml 7 http://polyglot.readthedocs.io  \\x0c294  8  Mohamed Seghir Hadj Ameur et al. / Att-seq2seq: A stranded GRU encoder and attention-based decoder. 4: Results for the English-to-Arabic transliteration when varying the encoder-decoder hidden sizes  Figure 4 shows the eﬀect of varying the network size (the number of neurons in each layer of the encoder-decoder architecture) reported in terms of Character Error Rate (CER) for the Bi-Att-seq2seq model. Results  The Word Error Rates (WERs) and Character Error Rates (CERs) obtained by all the investigated sequence-to- sequence models are provided in Table 5a and Table 5b for the tasks of transliteration from English-to-Arabic and Arabic-to-English respectively. Another problem is the absence of some Arabic character sounds in the English language which often get conﬂicted, such as the sounds of the Arabic letters “(cid:9)”, “ (cid:27)(cid:9)” and “ (cid:8)(cid:7)”. [7] D. Bahdanau, K. Cho, Y. Bengio, Neural machine translation by jointly learning to align and translate, arXiv preprint arXiv:1409.0473. [ [9] Y. Shao, J. Nivre, Applying neural networks to english-chinese named entitytransliteration, in: Sixth Named Entity Workshop, joint with 54th  [10] A. Finch, L. Liu, X. Wang, E. Sumita, Target-bidirectional neural models for machine transliteration, ACL 2016 (2016) 78. [',\n",
              " 'Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 937–947,  Valencia, Spain, April 3-7, 2017. As mono- lingual baselines, we use the skip-gram (SG) and CBOW methods of Mikolov et al. ( We trained with an embedding dimension of 200 for all data sizes as a larger dimension turned out to be helpful in capturing information from the source side.1  3.2 Results Figure 1 shows correlations with human judgment in the WordSim353 task. tent beneﬁt was gained by using source languages for which translation with English is simpler. Lan- guage modeling is a syntax-oriented task, yet syn- tax varies greatly between the languages we train the CLWEs on. A dimension of 100 yielded a good compromise between the smaller and larger training data sizes, while an order 5 MKN model performed slightly better than its lower-order brethren.4  Interestingly, MKN strongly outperforms the LSTM on low quantities of data, with the LSTM language model not reaching parity until between 16k and 32k sentences of data. This suggests that the English target embeddings are gleaning simi- lar information from each of the languages, infor- mation likely to be more semantic than syntactic, given the syntactic differences between the lan- guages. In Proceedings of the Seven- teenth Conference on Computational Natural Lan- guage Learning, pages 183–192. The expressive power of word em- beddings. Development of a WFST based speech recognition system for a resource deﬁ- cient language using machine translation. Learning bilingual word representations by marginalizing alignments. Software frame- work for topic modelling with large corpora. Rui Wang, Hai Zhao, Sabine Ploux, Bao-Liang Lu, and Masao Utiyama.',\n",
              " 'Analogies Explained: Towards Understanding Word Embeddings  Carl Allen 1 Timothy Hospedales 1  Abstract  Word embeddings generated by neural network methods such as word2vec (W2V) are well known to exhibit seemingly linear behaviour, e.g. the embeddings of analogy “woman is to queen as man is to king” approximately describe a paral- lelogram. 2014) are amongst the best known and on which we focus. 2013b; Levy & Goldberg, 2014a), e.g. the respective embeddings of analogies, or word rela- tionships of the form “wa is to wa∗ as wb is to wb∗”, often satisfy wa∗ − wa + wb ≈ wb∗, where wi is the embedding 1School of Informatics, University of Edinburgh. Correspondence to: Carl Allen <carl.allen@ed.ac.uk>. p(W) > 0, ∀W ⊆E,|W| < l, where (throughout) “|W| < l” means |W| sufﬁciently less than l.  The Relationship between W and C Several works (e.g. Hashimoto et al. ( Paraphrasing in Explicit Embeddings  Lem 1 applies to full rank PMI vectors, without reconstruc- tion error or case (ii) false positives (Sec 5.3), explaining the linear relationships observed by Levy & Goldberg (2014a). For any word sets W, W∗⊆E, |W|,|W∗| < l: wW∗ = wW + C† Proof. More generally, by Cor 2.1 we see that (9) is satisﬁed by uA ≈ − wW+− wW− if {wx∗,W } ≈P {wx,W +} ∀(wx, wx∗) ∈ SA for common word sets W +,W ⊆E and each pair of para- phrasing word sets exhibit similar dependence. Let W =W x, W∗ =W x∗ for x∈{a, b} in instances of Cor 2.1 and take the difference. Analogies in W2V embeddings  −  As with paraphrases (Sec 5.5), the results for analogies can be extended to W2V embeddings by including the shift term appropriately throughout. auxiliary  sol  permitting  reign  royal  crown  princess  lord  prince  queen  king  man  wK − wM + wW woman  \\x0cAnalogies Explained: Towards Understanding Word Embeddings  Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. Distributed representations of words and phrases and their compositionality. In Association for Computational Linguistics, 2017. Levy, O. and Goldberg, Y. Linguistic regularities in sparse and explicit word representations.',\n",
              " 'Massively Multilingual Neural Machine Translation  Roee Aharoni∗ Bar Ilan University  Ramat-Gan  Israel  Melvin Johnson and Orhan Firat  Google AI  Mountain View  California  roee.aharoni@gmail.com  melvinp,orhanf@google.com  9 1 0 2    l u J    2      ] L C . Our experiments on the publicly available TED talks dataset (Qi et al., 213k # of examples 198.5k 12.95 baselines 22.56 16.67 27.68 one-to-many many-to-many 14.25 24.9 Table 3: En→X test BLEU on the TED Talks corpus  167k 23.31 30.54 27.95  203k 30.33 35.89 33.26  211k 23.66 27.62 24.16  resource setting the baselines have very few train- ing examples to outperform the many-to-one mod- els, while in the higher resource setting they have access to more training data. Table 3 shows the results of our massively multilingual models and bilingual baselines when evaluated out-of-English. For example, while the baseline model batches include only one language in the source and one language in the target, the many- to-many model includes 59 languages in each side with a strong bias towards English. 2018) propose to share the entire network, while using a contex-  tual parameter generator that learns to generate the parameters of the system given the desired source and target languages. Regard- ing massively multilingual models, Neubig and Hu (2018) explored methods for rapid adaptation of NMT to new languages by training multilin- gual models on the 59-language TED Talks cor- pus and ﬁne-tuning them using data from the new languages. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. In Proceedings of the 27th International Conference on Computational Linguistics, Santa Fe, New Mexico, USA. Multi-task learning for mul- In Proceedings of the tiple language translation. Conference on Empirical Methods in Natural Lan- guage Processing. Toward multilingual neural machine trans- lation with universal encoder and decoder. arXiv preprint arXiv:1609.08144.',\n",
              " 'Vol.50 (001) 153-158 (2018)  27   http://doi.org/10.26692/sujo/2018.01.00                                     SINDH UNIVERSITY RESEARCH JOURNAL (SCIENCE SERIES)         Artificial Intelligence Mark-up Language Based Written and Spoken Academic Chatbots using Natural      Language Processing  ADNAN. A. ARAIN, A. MANZOOR*, K. BROHI**, K. HASEEB***, I. A. HALEPOTO****, I. A.  KOREJO**     Department of Telecommunication Engineering Systems Quaid-e-Awam University Nawabshah      Received 2   th4    October   7201   th25  February 2018    and Revised   Abstract:  Chatbot  is  an  intelligent  conversational  system  that  interacts  with  humans  via  natural  languages,  where  natural  language  processing  utilizes  computational  methods  to  learn,  understand,  and  generate  human  language  contents. This would be a  quick way to acquire information without the need to traverse the entire website and is also applicable to  any academic or educational  websites, such as schools, colleges, universities, or any institution. Semantic  interpretation  includes  the  production  of  a  depiction  (conceptual  graph  and  frames or other knowledge representation technique) of  the meaning of a sentence, whereas the incorporation of  global  knowledge  contains  the  generation  of  an  extended  representation  of  a  sentence’s  meaning  to  completely  understand  the  meaning  of  that  sentence,  upon which the output will be utilized by the application  system. A  significant  progress  in  this  realm  is  the  Chatbot  (chatterbot);  a  conversational  agent  that  uses  natural  languages  to  the  communication  with users/administration and accessing  required  information  is  time  consuming,  as  it  requires  an  employee  or  an  academic  administration  staff  to  spend  appropriate  information. 2007)  designed  a  Chatbot  that  simulates  a  historical  figure. Kowalski  and  Goldstein  (Kowalski,  et  al., 2009)  developed  two  case  studies  for  security  training  using  (Gunning  and  Forslund, 2013) developed a self-learning dialog system  that  has  the  ability  to  interpret  natural  languages,  and  they use Twitter® as a source of knowledge to generate  responses. A  significant  part  of  any  Chatbot  is  its  knowledge  base,  or  database. Shawar,  B.  A.,  and  E.  Atwell,  (2007). Different  measurements  metrics  to  evaluate  a  chatbot  system. Com/Pandora/Pics/Chatterbotsgonative. Kowalski,  S.,  K.  Pavlovska,  and  M.  Goldstein,  (2009).',\n",
              " 'Received September 30, 2020, accepted October 12, 2020, date of publication October 15, 2020, date of current version October 28, 2020. The foun- dation of Urdu is lies in Arabic, Persian and most of the South Asian languages. The structure of the paper categorised into the following sections: section II presents the Roman Urdu in which the impact and inﬂuences of the Roman Urdu language is dis- cussed. Local users need to use Roman Urdu in daily life. Mostly ‘ain’ and ‘alif’ occurs at the start of the word like ‘adal’ and ‘alag’ both have vowel letter ‘a’ in Roman Urdu that is equivalent to diacritic mark ‘zabar’ in Urdu as shown in Figure 5. The general- ized form of the rule comes forward after all the special rules. RUTUT Based on Character Substitution Rules and Unicode Mapping  FIGURE 14. Character mapping is the phase in which a preprocessed and rule-based substitutions are applied to Roman Urdu and a form of Roman Urdu is  189832  VOLUME 8, 2020  \\x0cM. Shahroz et al.: A. COMPARISON OF THE GOOGLE ONLINE TRANSLATOR RESULTS First, the Google translator [74] results are illustrated in this ﬁgure because Google is from one of the largest industry in the world that has a Google online translator for lan- guage translations. The character mapping module based on Unicodes of Urdu characters against the Roman Urdu characters that convert the Roman Urdu form into Urdu Script. VOLUME 8, 2020  189839  \\x0cM. Shahroz et al.: 05869  [37] M. Z. Asghar, A. Sattar, A. Khan, A. Ali, F. Masud Kundi, and S. Ahmad, ‘‘Creating sentiment lexicon for sentiment analysis in Urdu: The case of a resource-poor language,’’ Expert Syst., Cham, Switzerland: Springer, 2020, pp.',\n",
              " \"IJCSNS International Journal of Computer Science and Network Security, VOL.17 No.12, December 2017   213   Lexical normalization of roman Urdu text   Zareen Sharf, Dr Saif Ur Rahman   PhD Scholar SZABIST    Associate Professor SZABIST        Summary  Social  media  text  usually  comprises  of  short  length  messages,  which  typically  contain  a  high  percentage  of  abbreviations,  typos, phonetic substitutions and other informal ways of writing. These inconsistencies cause a problem of data sparsity in  basic  natural  language  processing  tasks  such  as  Urdu  word segmentation, part of speech tagging, spell checking,  machine translation, etc. Uddin  and  Begum  modified  and  modernized  Gilchrist's system by introducing a scheme that provided a  one  to  one  mapping  for  Urdu  and  Hindi  characters. After  identifying  ill-formed  words,  they  are  compared  with  the  confusion  set  and  the  best  possible  candidate  based  on  morphophonemic variation is selected for normalization. (Brocki  and  Łukasz  2012)  A  rule  based-approach  was  proposed with over 1500 manually defined rules applied  for achieving normalization of text. Many  versions  of  Soundex  algorithm  have  been  proposed  and  successfully   issues   the   implemented to overcome the issues posed by large data  sets  ever  since  it  was  first  introduced  in  1981. We  extracted all possible variants of each word from ijunoon  transliteration  service  that  led  us  to  devise  the  rules  for  transformation and standardization. International  Conference   [9]  Grzegorz and Chrupala 2014. [20] Li Chen and Liu Yang 2014. Soroosh,   [24] Malik,  Abbas  M,  and  Boitet,  2008. Proceedings  of  the  22nd  International  Conference  on  Computational  Linguistics, Manchester, UK. Compensating for speaker or lexical variabilities in speech  for emotion recognition.\",\n",
              " 'Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 127–135,  Honolulu, October 2008. In general, efforts on building subjectivity analy- sis tools for other languages have been hampered by the high cost involved in creating corpora and lexical resources for a new language. The work closest to ours is the one reported in (Mihalcea et al., In that work, we found that the projection of annotations across par- allel texts can be successfully used to build a cor- pus annotated for subjectivity in the target language. Figure 2 illustrates this experiment. 130  3.3 Experiment Three: Machine Translation of  Target Language Training Data  The third experiment is similar to the second one, except that we reverse the direction of the transla- tion. The results obtained by running the three experi- ments on Romanian are shown in Table 2. Therefore labeling this data using the OpinionFinder tool and projecting the labels onto a fully inﬂected human- generated Romanian text provides more accurate classiﬁcation results, as compared to a setup where the training is carried out on machine-translated Ro- manian text (experiment two). It is also interesting to note that the labeling of the training set was per- formed using a subjectivity classiﬁer developed for English, which takes into account a large, human- annotated, subjectivity lexicon also developed for English. 135  L. Lloyd, D. Kechagias, and S. Skiena. H. Takamura, T. Inui, and M. Okumura. Latent variable models for semantic orientations of phrases. Y. Hu, J. Duan, X. Chen, B. Pei, and R. Lu.',\n",
              " 'The objective of this research is to develop and test a novel tactic to solve the issue of translation from Roman Urdu to the English language. 4, the description of translator along with its components and how we process Roman Urdu data, normalization of text and translation from Roman Urdu English language is shown. Moreover, we have also covered WH Questions and imperative sentences in our grammar. In this knowledge base, a data table for wordlist is created in which all information mandatory for syntax and semantic analysis is saved, such as the word, POS tag, its corresponding meaning and type needed for translation. It consists of terminals (POS tags) and non-terminals, which generates a set of production rules. It shows a conversion process of Roman Urdu into the English language. It performs an absolute reading of source language (Roman Urdu), which is in the form of the input string. Spell checker and learning agent  The spell checker is embedded along with the scanner which performs spell checking of the tokens with the assistance of data available in the knowledge base model. Internal view of Roman Urdu Translator. The input of POS Tagger is a stream of Tokens, which are assigned its linguistic information at runtime by parsing through the syntax of grammar rules. Competing interest statement  The authors declare no conﬂict of interest. [5] Dara Becker, Kashif Riaz, A study in Urdu corpus construction, in: Proceedings of the 3rd Workshop on Asian Language Resources and International Standardization, 12, Association for Computational Linguistics, 2002, pp. http://www.cle.org.pk/software/loca  [18] A. Hardie, Developing a tagset for automated part-of-speech tagging in Urdu, in:  lization.htm.',\n",
              " 'In order to improve the quality of translations, it is important  toexploitavailable  resources  efficiently. features  and  use   them   We  do  the  CLIR  task  of  CLEF  2008  and  2009:  “Retrieving  Persian  documents  from  queries  in  English”  for  evaluating  the  proposed  method. Also,  in  this  section,  we  discuss  impact  of  different  features  on  constructing  the  LTR  based  translation model and the effect of size and quality of  corpora on the accuracy of CLIR. In  this  research,  we  used  this  idea  for  defining  different  features  and  finding  the  correct  translations  of query words. For example, some researches ([29], [30]) used Latent  Semantic  Indexing  (LSI)  for  query  translation and mapped the queries and documents into  a multilingual space. Thus,  the  scoring  and  ranking  functions  will  be  as   The  proposed  method  has  three  main  steps:  constructing  the  training  data,  learning  a  ranking  model,  and  using  the  ranking  model  for  ranking  translations. Translation  probability  difference: The difference  between  the  translation  probability  of  a  candidate  translation  and  the  highest  translation  probability  in  translation  candidates  of  the  source  word  is  another  feature that we use in this paper. pi is defined as the number of documents  containing wi divided by N.  For  each  word  w, we  calculate  the  correlation  of  that  word  with  other  words  of  the  sentence  that  contains w as:  (cid:1842)(cid:1839)(cid:1835)((cid:1875),(cid:1875)(cid:1861)),  (6)  (cid:1829)((cid:1875),(cid:1845))= (cid:963)  (cid:1875)(cid:1861)(cid:1488)(cid:1845),(cid:1875)(cid:1861)(cid:3405)(cid:1875)  Where S is the sentence containing w. S is the sentence  of training parallel corpus that we extracted the pair of  source-target  language  words  from  it. We  use  LTR  methods  for  constructing  a  ranking  model  by  employing  the  train  data. Using this resource we have 13 OOV words, which is  lower  than  comparable  corpus  based  method  and  shows its effect on the results. In  fact,  each  resource suggests the most frequent translations of the  source  word  as  translation  of  the  word. The  main  problem  of  IBM  model-1  in  translating  queries  is  that  it  does  not  consider  the  context  in  extracting  translations  and  the  translations  extracted  using this method could have ambiguity. [29](cid:3) S.T.  Dumais,  T.K.  Landauer  and  M.L.  Littman,  “Automatic  cross-linguistic  information  retrieval  using  Latent  Semantic  Indexing,” Inproceedings of the 19st ACM SIGIR Conference  on  Research  and  Development  in  Information Retrieval  (SIGIR), Zurich, Switzerland, 1996, pp.',\n",
              " 'Sequence to Sequence Networks for Roman-Urdu to   20th International Multitopic Conference (INMIC’ 17)   Urdu Transliteration    Mehreen Alam, Sibt ul Hussain   mehreen.alam@nu.edu.pk, sibtul.hussain@nu.edu.pk   Reveal Lab, Computer Science Department, NUCES   Islamabad, Pakistan              Abstract—  Neural  Machine  Translation  models  have  replaced  the  conventional  phrase  based  statistical  translation  methods since the former takes a generic, scalable, data-driven  approach rather than relying on manual, hand-crafted features. These  include:  bidirectional  models  of  [3]  having  encoders that take into account the words in left to right order  as well as right to left; the reverse encoder-decoder of [9] that  takes  the  input  of  the  encoder  in  right  to  left  manner;  Character-based  models  of  [10]  that  feed  every  encoder  not  with words in the sentence but with the letter sequence making  the  sentence. Favoring   recognize  the  morphologically rich languages, the downside of this property  is that FastText does better on learning syntactic  embeddings  than  the  semantic  embeddings  learning  [19]. These have achieved state- of-the-art  results  on  various  natural  language  processing  domains  of  topic  modeling,  text  summarization  and  word  sense  distributed  representation  of  Urdu language  has  been  done  by  Facebook  [18]. Though Urdu is a morphologically rich language and used  by 0.1 billion users, to the best of our knowledge, no work is  done  in  building  a  publically  available  Roman-Urdu  to  Urdu  parallel  corpus. For  this,  we  downloaded  5000  most  frequently  Urdu  words  from [36] and 100 variations of each of the 5000 words were  collected  through  crowd-sourcing    Data  augmentation  was  done by using each of the 5000 Urdu words and substituting  each word in the data  according to its distribution in the data  collected  through  transliteration. 3)  We  also  created  a  dictionary  for  one  to  one  mapping  between Roman-Urdu and Urdu. It  is  worth  mentioning  that  dictionary-based  one-to-one  mapping  of  Roman-Urdu  to  Urdu  dictionary  was  only  successful  for  seen  words  not  needing  any  contextual  information. Hochreiter,  S.  and  J.  Schmidhuber,  Long  short-term  memory. arXiv preprint arXiv:1508.04025, 2015. Pennington, J., R. Socher, and C.D. Manning. Semantic  Similarity  Analysis  of  Urdu Documents. Addressing  the  rare  word  in  neural  machine  problem  translation.',\n",
              " 'Regularization techniques for ﬁne-tuning in neural machine translation  Antonio Valerio Miceli Barone Barry Haddow  Ulrich Germann Rico Sennrich  School of Informatics, The University of Edinburgh  {amiceli, bhaddow, ugermann}@inf.ed.ac.uk  rico.sennrich@ed.ac.uk  Abstract  for  We investigate techniques super- vised domain adaptation for neural ma- chine translation where an existing model trained on a large out-of-domain dataset is adapted to a small in-domain dataset. For the out-of-domain systems, we use training data from the WMT shared translation task,2 which is considered permissible for IWSLT tasks, including back-translations of monolingual training data (Sennrich et al., 2017) as the neural machine translation toolkit. 4 Conclusion  We investigated ﬁne-tuning for domain adapta- tion in neural machine translation with different amounts of in-domain training data, and strategies to avoid overﬁtting. References Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. Computer Speech & Language, 20(4):382–399. Association for Computational Linguistics. Rico Sennrich, Barry Haddow, and Alexandra Birch. Association for Computa- tional Linguistics. Ilya Sutskever, Oriol Vinyals, and Quoc V. Le. In Proceedings of the 2015 Conference on Empirical Methods in Natu- ral Language Processing, pages 1059–1065, Lisbon, Portugal. ings of the International Workshop on Spoken Lan- guage Translation 2015, Da Nang, Vietnam.',\n",
              " 'An Effective Approach to Unsupervised Machine Translation  Mikel Artetxe, Gorka Labaka, Eneko Agirre  IXA NLP Group  University of the Basque Country (UPV/EHU)  {mikel.artetxe, gorka.labaka, e.agirre}@ehu.eus  9 1 0 2    l u J    4 2      ] L C . Our experiments on WMT 2014/2016 French- English and German-English show the effective- ness of our approach, as our proposed system out- performs the previous state-of-the-art in unsuper- vised machine translation by 5-7 BLEU points in all these datasets and translation directions. 2016), our method takes two initial models in op- posite directions, and deﬁnes an unsupervised op- timization objective that combines a cyclic con- sistency loss and a language model loss over the two monolingual corpora E and F :  L = Lcycle(E) + Lcycle(F ) + Llm(E) + Llm(F )  The cyclic consistency loss captures the intu- ition that the translation of a translation should be close to the original text. For that purpose, we estimate the per-word entropy in the target language corpus using an n-gram language model, and penalize higher per-word entropies in machine translated text as follows:4 Llm(E) = LP· max(0, H(F ) − H(TE→F (E)))2 4We initially tried to directly minimize the entropy of the generated text, but this worked poorly in our preliminary ex- periments on English-Spanish (note that we used this lan- guage pair exclusively for development to be faithful to our unsupervised scenario at test time). This does not only guarantee that the probability estimates are meaningful as discussed previously, but it also discards the ungrammatical phrases al- together, as both the source and the target n-grams must have occurred in the original monolingual texts to be present in the resulting phrase-table. ∗Detokenized BLEU equivalent to the ofﬁcial mteval-v13a.pl script. Our unsupervised tuning implementation is based on Z-MERT (Zaidan, 2009), and we use FastAlign (Dyer et al., Association for Computational Linguistics. Mikel Artetxe, Gorka Labaka, and Eneko Agirre. Minimum error rate train- In Proceed- ing in statistical machine translation. Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. Association for Computa- tional Linguistics. 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 86–96, Berlin, Germany.',\n",
              " 'The architecture addresses two major problems occurring in machine translation, namely the poor performance of direct translation from a highly-inﬂected and morphologically complex language into morphologically poor languages, and the data sparseness issue, which becomes a signiﬁcant challenge under low-resource conditions. Section 4 discusses the factored MT approach. In this work, we focus on the annotation of the source side (i.e., Arabic) using some popular linguistic features to determine whether these features will improve the quality of Arabic → Chinese translation. For  the  baseline  approach,  we  test  the  tokenization script  tokenizer.perl  of  Moses  [34],  which  simply  separates  the  punctuation  marks  of  Arabic  side  using  the  same  default  as  English   We also experiment with MADAMIRA [35], a state-of-the-art morphological analyzer for the  Arabic  language  to  implement  the  Penn  Arabic  Treebank  (ATB)  scheme  as  morphology-aware  tokenization. As shown in Table 1, the results of the MADAMIRA tagger annotate each word by its POS tag. Thus, morphology analysis is necessary to handle data sparseness and improve translation quality. For example, verbs have person, gender, number, voice, and mood, whereas nouns have case, state, gender, gloss, number, and the attached proclitic DET. An example of the Arabic features in our approach. These  tags  provide  the  linguistic  knowledge  and  syntactic  role  of  each  token  in  the  context,  which  helps  in  information   The basic POS for Arabic words has many categories: noun, e.g., ﺏﺎﺘﻛ (ktAb) “book” or ﺐﺘﻛ (ktb)   dataset extracted from the Penn Arabic Treebank. Papineni,  K.;  Roukos,  S.;  Ward,  T.;  Zhu,  W.-J.  BLEU:  A  method  for  automatic  evaluation  of  machine  translation. In  Proceedings  of  the  2004  Conference on Empirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain, 25–26 July  2004; pp. To perform a manual analysis, we randomly selected sentences from the system output over the baseline, tokenized models and best-factored models as shown in Figure 5, and observed the following:  \\x0cFuture Internet 2019, 11, 22  13 of 17  (1) Alleviate issues of dropping translations  The baseline and both tokenized models ignore or drop the translation of some words in the dataset, whereas this condition occurs at a lower rate in the factored models. Post, M.; Kumar, G.; Lopez, A.; Karakos, D.; Callison-Burch, C.; Khudanpur, S. Improved speech-to-text translation with the Fisher and Callhome Spanish–English speech translation corpus.',\n",
              " 'Transfer Learning for Low-Resource Neural Machine Translation  Barret Zoph1, Deniz Yuret2, Jonathan May1, Kevin Knight3 1Information Sciences Institute, University of Southern California  {zoph, jonmay}@isi.edu  2Computer Engineering, Koc¸ University  dyuret@ku.edu.tr  3Information Sciences Institute &  Computer Science Department, University of Southern California  knight@isi.edu  Abstract  The encoder-decoder framework for neu- ral machine translation (NMT) has been shown effective in large data scenarios, but is much less effective for low-resource lan- guages. In the French-English to Uzbek-English example, as a result of the ini- tialization, the English word embeddings from the parent model are copied, but the Uzbek words are initially mapped to random French embed- dings. We also experiment with or- dinary L2 regularization, but ﬁnd it does not sig- niﬁcantly improve over the parameter freezing de- scribed above. There is a large gap  Language SBMT NMT Xfer Final Hausa 24.0 18.7 Turkish 16.8 Uzbek Urdu 14.5  16.8 11.4 10.7 5.2  23.7 20.4 17.9 17.9  21.3 17.0 14.4 13.8  Table 2: Our method signiﬁcantly improves NMT results for the translation of low-resource lan- guages into English. For our NMT system, we use development sets for Hausa, Turkish, Uzbek, and Urdu to tune the learning rate, parameter initialization range, dropout rate and hidden state size for all the ex- periments. Overall our method allows the NMT system to reach competitive scores and beat the SBMT system in one of the four language pairs. Table 3 shows the results of re-scoring. We see that the opti- mal setting for transferring from French-English to Uzbek-English in terms of BLEU performance  Figure 2: Our NMT model architecture, show- ing six blocks of parameters, in addition to source/target words and predictions. [Galley et al.2006] M. Galley, J. Graehl, K. Knight, D. Marcu, S. DeNeefe, W. Wang, and I. Thayer. [Luong et al.2015b] T. Luong,  I. Sutskever, Q. Le, O. Vinyals, and W. Zaremba. Neural machine translation by  [Neco and Forcada1997] R. Neco and M. Forcada. Transfer learning for speech and language processing. arXiv preprint arXiv:1511.06066.',\n",
              " 'Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 40–47,  Suntec, Singapore, 6-7 August 2009. Different  equivalence  classes  are  made of all the words in the lexicon using the match  of prefix of an already defined length. Kumar  and  Siddiqui  (2008)  propose  an  algorithm  for  Hindi  stemmer  which  calculates  n- grams  of  the  word  of  length  l.  These  n-grams  are  treated  as  postfixes. The  second  technique  is  based  on  n-grams. On the other hand rule-based techniques  when  applied  to  morphologically  rich  languages  reveal  accuracy  up  to  99.6%  (Thabet  2004). Therefore,  the  current  work  uses  a  rule  based  approach  with  a  variation  from  lexical look-up, to develop a stemmer for Urdu. Figure 1: Flow Chart for the Stemming Process     An  Urdu  word  is  composed  of  a  sequence  of  prefixes, stem and postfixes. Postfix  Extraction:  This  process  separates  the  postfix  from  word  and  performs  the  post-processing  step, if required, for generating the surface form. Development  of  PrGEL:  The  PrGEL  contains  all  those  words  from  which  a  prefix  cannot  be  extracted. hathi (elephant) may be truncated  For example,  (cid:370)(cid:56)(cid:138)(cid:253) to  (cid:136)(cid:56)(cid:138)(cid:253) hath (hand), which is incorrect removal of the  postfix ی (letter choti-yay). Manual Corrections  Manual  inspection  is  needed  to  fix  the  errors  generated by the automated system. Testing  Phase  1:  The  corpora  C1  and  C2  are  used  which  have  combined  11,339  unique  words. Naseem,  T.,  Hussain,  S.  2007.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjAU6sI0mGgU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}